# ================================================================================
# Limpeza de Recursos Legados - Data Lakehouse
# ================================================================================
# Descri√ß√£o: Remove componentes √≥rf√£os e obsoletos para economizar custos
# Componentes: Crawlers legados, Jobs obsoletos, Tabelas n√£o utilizadas
# Atualizado: 05/11/2025 - P√≥s-valida√ß√£o QA e refatora√ß√£o Silver‚ÜíGold
# ================================================================================

terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# ================================================================================
# NOTA IMPORTANTE: ESTRAT√âGIA DE REMO√á√ÉO
# ================================================================================
# Este arquivo N√ÉO cria recursos. Ele documenta os recursos a serem removidos.
# 
# Para remover recursos gerenciados pelo Terraform:
# 1. Remova os blocos de recurso dos arquivos .tf originais
# 2. Execute: terraform plan
# 3. Execute: terraform apply (Terraform destruir√° os recursos removidos)
#
# Para remover recursos N√ÉO gerenciados pelo Terraform:
# 1. Use os data sources abaixo para verificar exist√™ncia
# 2. Execute os comandos AWS CLI comentados em cada se√ß√£o
# ================================================================================

# ================================================================================
# VARI√ÅVEIS
# ================================================================================

variable "aws_region" {
  description = "Regi√£o AWS"
  type        = string
  default     = "us-east-1"
}

variable "database_name" {
  description = "Nome do database Glue Catalog"
  type        = string
  default     = "datalake-pipeline-catalog-dev"
}

variable "legacy_crawler_performance_alerts_name" {
  description = "Nome do crawler √≥rf√£o de performance alerts"
  type        = string
  default     = "datalake-pipeline-gold-performance-alerts-crawler-dev"
}

variable "legacy_job_performance_alerts_name" {
  description = "Nome do job legado de performance alerts"
  type        = string
  default     = "datalake-pipeline-gold-performance-alerts-dev"
}

variable "test_job_silver_name" {
  description = "Nome do job de teste Silver"
  type        = string
  default     = "silver-test-job"
}

variable "legacy_table_silver_car_telemetry_new" {
  description = "Nome da tabela Silver legada"
  type        = string
  default     = "silver_car_telemetry_new"
}

# ================================================================================
# 1. REMO√á√ÉO: Crawler Legado de Performance Alerts (√ìrf√£o)
# ================================================================================
# Justificativa: Tabela 'performance_alerts_log' foi deletada em 05/11/2025
# Impacto: Economia de ~$0.44/hora de execu√ß√£o + limpeza do cat√°logo
# Status: Crawler √≥rf√£o (target n√£o existe)

data "aws_glue_crawler" "legacy_performance_alerts_crawler" {
  name = var.legacy_crawler_performance_alerts_name
}

# A√á√ÉO MANUAL: Remover via AWS CLI
# aws glue delete-crawler \
#   --name datalake-pipeline-gold-performance-alerts-crawler-dev \
#   --region us-east-1

# Ou via Console AWS:
# 1. AWS Glue Console ‚Üí Crawlers
# 2. Selecionar: datalake-pipeline-gold-performance-alerts-crawler-dev
# 3. Actions ‚Üí Delete

# ================================================================================
# 2. REMO√á√ÉO: Job Legado Gold Performance Alerts (Substitu√≠do)
# ================================================================================
# Justificativa: Substitu√≠do por 'gold-performance-alerts-slim-dev' em 05/11/2025
# Impacto: Economia de ~$0.44/DPU-hora + redu√ß√£o de complexidade
# Status: Marcado como "legado" no invent√°rio

data "aws_glue_job" "legacy_performance_alerts_job" {
  name = var.legacy_job_performance_alerts_name
}

# A√á√ÉO MANUAL: Remover via AWS CLI
# aws glue delete-job \
#   --job-name datalake-pipeline-gold-performance-alerts-dev \
#   --region us-east-1

# Ou via Console AWS:
# 1. AWS Glue Console ‚Üí ETL Jobs
# 2. Selecionar: datalake-pipeline-gold-performance-alerts-dev
# 3. Actions ‚Üí Delete

# ================================================================================
# 3. REMO√á√ÉO: Job de Teste Silver (Desenvolvimento)
# ================================================================================
# Justificativa: Job de teste/desenvolvimento - n√£o utilizado em produ√ß√£o
# Impacto: Economia de custos + limpeza do ambiente
# Status: Marcado como "desenvolvimento" no invent√°rio

data "aws_glue_job" "test_silver_job" {
  name = var.test_job_silver_name
}

# A√á√ÉO MANUAL: Remover via AWS CLI
# aws glue delete-job \
#   --job-name silver-test-job \
#   --region us-east-1

# ================================================================================
# 4. VERIFICA√á√ÉO: Tabela Silver Car Telemetry New (Se ainda existir)
# ================================================================================
# Justificativa: Substitu√≠da por 'silver_car_telemetry' - marcada como deletada no hist√≥rico
# Impacto: Limpeza do cat√°logo (sem custo direto)
# Status: Deve ter sido removida, mas verificar para garantir

data "aws_glue_catalog_table" "legacy_silver_table" {
  database_name = var.database_name
  name          = var.legacy_table_silver_car_telemetry_new
}

# A√á√ÉO MANUAL: Remover via AWS CLI (se ainda existir)
# aws glue delete-table \
#   --database-name datalake-pipeline-catalog-dev \
#   --name silver_car_telemetry_new \
#   --region us-east-1

# ================================================================================
# 5. A√á√ÉO P√ìS-REMO√á√ÉO: Limpeza de Dados √ìrf√£os no S3
# ================================================================================
# Ap√≥s remover tabelas do Glue Catalog, os arquivos Parquet no S3 permanecem
# e continuam gerando custos de armazenamento (~$0.023/GB/m√™s)

# DADOS √ìRF√ÉOS IDENTIFICADOS:
# 1. s3://datalake-pipeline-gold-dev/performance_alerts_log/
#    - Tabela deletada, dados √≥rf√£os
#    - Executar crawler retornou 0 tabelas criadas
#
# 2. s3://datalake-pipeline-silver-dev/silver_car_telemetry_new/ (se existir)
#    - Tabela migrada para silver_car_telemetry

# A√á√ÉO MANUAL: Listar e revisar dados antes de deletar
# aws s3 ls s3://datalake-pipeline-gold-dev/performance_alerts_log/ --recursive --human-readable --summarize

# A√á√ÉO MANUAL: Backup (opcional, se necess√°rio auditoria)
# aws s3 sync \
#   s3://datalake-pipeline-gold-dev/performance_alerts_log/ \
#   s3://datalake-pipeline-archive-dev/backups/performance_alerts_log_backup_20251105/

# A√á√ÉO MANUAL: Deletar dados √≥rf√£os (CUIDADO: A√ß√£o irrevers√≠vel!)
# aws s3 rm s3://datalake-pipeline-gold-dev/performance_alerts_log/ --recursive

# Verificar espa√ßo liberado
# aws s3 ls s3://datalake-pipeline-gold-dev/ --recursive --summarize

# ================================================================================
# OUTPUTS - Informa√ß√µes sobre recursos a remover
# ================================================================================

output "legacy_resources_summary" {
  description = "Resumo dos recursos legados identificados para remo√ß√£o"
  value = {
    crawlers_to_remove = [
      var.legacy_crawler_performance_alerts_name
    ]
    jobs_to_remove = [
      var.legacy_job_performance_alerts_name,
      var.test_job_silver_name
    ]
    tables_to_verify = [
      var.legacy_table_silver_car_telemetry_new
    ]
    s3_paths_to_clean = [
      "s3://datalake-pipeline-gold-dev/performance_alerts_log/",
      "s3://datalake-pipeline-silver-dev/silver_car_telemetry_new/ (verificar exist√™ncia)"
    ]
  }
}

output "estimated_cost_savings" {
  description = "Estimativa de economia mensal (USD) - valores aproximados"
  value = {
    crawler_executions  = "~$2-5/m√™s (1 crawler √≥rf√£o removido)"
    unused_jobs         = "~$0 (jobs n√£o executados, mas limpeza de ambiente)"
    s3_storage_cleanup  = "~$0.50-2/m√™s (dependendo do volume de dados √≥rf√£os)"
    total_estimated     = "~$2.50-7/m√™s + redu√ß√£o de complexidade operacional"
  }
}

output "cleanup_checklist" {
  description = "Checklist de a√ß√µes manuais para limpeza completa"
  value = {
    step_1 = "‚úÖ Revisar data sources acima para confirmar recursos existem"
    step_2 = "üóëÔ∏è Executar comandos AWS CLI para deletar crawlers/jobs legados"
    step_3 = "üìä Listar dados √≥rf√£os no S3 (aws s3 ls)"
    step_4 = "üíæ (Opcional) Fazer backup de dados para auditoria"
    step_5 = "üóëÔ∏è Deletar dados √≥rf√£os do S3 (aws s3 rm --recursive)"
    step_6 = "‚úÖ Validar remo√ß√£o e verificar economia de custos no Cost Explorer"
    step_7 = "üìù Atualizar INVENTARIO_AWS.md removendo recursos deletados"
  }
}

output "manual_commands_reference" {
  description = "Comandos AWS CLI prontos para execu√ß√£o (revisar antes de usar)"
  value = {
    delete_legacy_crawler = "aws glue delete-crawler --name ${var.legacy_crawler_performance_alerts_name} --region ${var.aws_region}"
    delete_legacy_job     = "aws glue delete-job --job-name ${var.legacy_job_performance_alerts_name} --region ${var.aws_region}"
    delete_test_job       = "aws glue delete-job --job-name ${var.test_job_silver_name} --region ${var.aws_region}"
    list_s3_orphan_data   = "aws s3 ls s3://datalake-pipeline-gold-dev/performance_alerts_log/ --recursive --summarize"
    delete_s3_orphan_data = "aws s3 rm s3://datalake-pipeline-gold-dev/performance_alerts_log/ --recursive"
  }
}

# ================================================================================
# NOTAS ADICIONAIS
# ================================================================================
# 
# 1. SEGURAN√áA: Sempre fa√ßa backup antes de deletar dados do S3
# 2. CUSTOS: Use AWS Cost Explorer para validar economia p√≥s-limpeza
# 3. AUDITORIA: Documente todas as remo√ß√µes para compliance
# 4. VALIDA√á√ÉO: Ap√≥s limpeza, execute o workflow e valide integridade do pipeline
# 5. DOCUMENTA√á√ÉO: Atualize INVENTARIO_AWS.md ap√≥s conclus√£o
#
# ================================================================================
#    - Redu√ß√£o de complexidade operacional
#    - Menor risco de erros por nomenclatura inconsistente
#    - Economia de tempo de desenvolvedores
#
# TOTAL ESTIMADO: $3.60-5.23/m√™s + economias operacionais indiretas
# ANUAL: ~$43-63/ano + melhor governan√ßa de dados
#
# ============================================================================
