# üöÄ Infraestrutura Terraform - AWS Glue Job Silver Consolidation

> **Migra√ß√£o Completa: Lambda Event-Driven ‚Üí Glue Job Scheduled**  
> Soluciona problema de duplicatas na Camada Silver com l√≥gica de Upsert/Consolida√ß√£o

---

## üìã Vis√£o Geral

Este pacote de infraestrutura Terraform provisiona um **AWS Glue ETL Job** para substituir a arquitetura Lambda baseada em eventos S3 por um processamento agendado com consolida√ß√£o de dados.

### üéØ Problema Resolvido

**Antes (Lambda):**
- Cada arquivo Bronze ‚Üí Execu√ß√£o Lambda ‚Üí Append no Silver
- M√∫ltiplos uploads do mesmo `carChassis` + `event_day` = **Duplicatas** ‚ùå

**Depois (Glue Job):**
- Job agendado (hor√°rio) ‚Üí L√™ dados novos + existentes ‚Üí Deduplica ‚Üí Sobrescreve parti√ß√µes
- Apenas **1 registro √∫nico** por `carChassis` + `event_day` ‚úÖ

---

## üì¶ Conte√∫do Entregue

### 1Ô∏è‚É£ **Infraestrutura Terraform** (`terraform/`)

| Arquivo | Descri√ß√£o | Status |
|---------|-----------|--------|
| `glue_jobs.tf` | **NOVO** - Recursos Glue Job (400+ linhas) | ‚úÖ Criado |
| `lambda.tf` | **MODIFICADO** - Removidos S3 triggers cleansing | üîÑ Atualizado |
| `variables.tf` | **MODIFICADO** - Adicionadas 12 vari√°veis Glue | üîÑ Atualizado |
| `deploy_glue_migration.ps1` | **NOVO** - Script de deploy automatizado | ‚úÖ Criado |
| `README_GLUE_TERRAFORM.md` | **NOVO** - Manual completo Terraform | ‚úÖ Criado |

**Recursos Provisionados:** 11 recursos AWS (S3, IAM, Glue, CloudWatch)

### 2Ô∏è‚É£ **Script PySpark** (`glue_jobs/`)

| Arquivo | Descri√ß√£o | Linhas |
|---------|-----------|--------|
| `silver_consolidation_job.py` | Script ETL completo com Upsert | 370+ |

**Funcionalidades:**
- ‚úÖ Job Bookmarks (processamento incremental)
- ‚úÖ 5 etapas de transforma√ß√£o (flatten, cleanse, enrich, partition)
- ‚úÖ Deduplica√ß√£o com Window functions
- ‚úÖ Dynamic Partition Overwrite

### 3Ô∏è‚É£ **Documenta√ß√£o Completa** (`docs/`)

| Documento | Conte√∫do | Linhas |
|-----------|----------|--------|
| `GLUE_JOB_SILVER_CONSOLIDATION.md` | Explica√ß√£o detalhada do script PySpark | 500+ |
| `MIGRATION_LAMBDA_TO_GLUE.md` | Guia de migra√ß√£o completo | 800+ |
| `ARCHITECTURE_DIAGRAM.md` | Diagramas visuais da arquitetura | 600+ |
| `COMMANDS_CHEATSHEET.md` | Comandos √∫teis (deploy, monitoramento, troubleshooting) | 700+ |
| `SUMMARY_GLUE_MIGRATION.md` | Resumo executivo | 300+ |

**Total:** ~3.270 linhas de c√≥digo + documenta√ß√£o

---

## üöÄ Quick Start

### Pr√©-requisitos

- ‚úÖ Terraform >= 1.0
- ‚úÖ AWS CLI configurado
- ‚úÖ Credenciais AWS com permiss√µes Admin
- ‚úÖ Python 3.x (para valida√ß√£o de sintaxe)

### Deploy em 3 Passos

```powershell
# 1. Navegar para diret√≥rio Terraform
cd terraform

# 2. Executar script de deploy automatizado
.\deploy_glue_migration.ps1

# 3. Confirmar aplica√ß√£o
# O script validar√° tudo e pedir√° confirma√ß√£o antes de aplicar
```

**OU deploy manual:**

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

---

## üìä Arquitetura

### Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARQUITETURA NOVA (Glue Job)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Landing (JSON)  ‚Üí  Bronze (Parquet)  ‚Üí  Silver (Parquet)
      ‚Üì                  ‚Üì                      ‚Üì
  S3 Event          Job Bookmarks         Consolidado
      ‚Üì                  ‚Üì                      ‚Üì
Lambda Ingestion   Glue Job (Hourly)     Sem Duplicatas ‚úÖ
 (mantido)         - Read New+Existing
                   - Transform (5 steps)
                   - Deduplicate (Window)
                   - Dynamic Overwrite
```

### Recursos Terraform

**‚úÖ Criados (11):**
- 2√ó S3 Buckets (scripts, temp)
- 1√ó S3 Object (script PySpark)
- 4√ó IAM (role + 3 pol√≠ticas)
- 1√ó Glue Job
- 1√ó Glue Trigger (agendado)
- 1√ó CloudWatch Log Group
- 1√ó Data Source (Account ID)

**‚ùå Removidos (2):**
- Lambda Permission (S3 ‚Üí Cleansing)
- S3 Bucket Notification (Bronze)

**‚ö™ Mantidos (sem altera√ß√µes):**
- Lambda Ingestion (Landing ‚Üí Bronze)
- Lambda Cleansing function (n√£o acionada)
- Todos os S3 buckets (landing, bronze, silver, gold)
- Glue Crawlers
- Athena Workgroup

---

## ‚úÖ Valida√ß√£o P√≥s-Deploy

```bash
# 1. Verificar Glue Job
aws glue get-job --job-name datalake-pipeline-silver-consolidation-dev

# 2. Verificar Trigger
aws glue get-trigger --name datalake-pipeline-silver-consolidation-trigger-dev

# 3. Verificar Script no S3
aws s3 ls s3://datalake-pipeline-glue-scripts-dev/glue_jobs/

# 4. Teste manual
aws glue start-job-run --job-name datalake-pipeline-silver-consolidation-dev

# 5. Monitorar logs
aws logs tail /aws-glue/jobs/datalake-pipeline-silver-consolidation-dev --follow
```

---

## üß™ Teste End-to-End

### Passo 1: Upload de Dados

```bash
# Arquivo 1: carChassis=5ifRW..., mileage=4321
aws s3 cp test_data/car_raw.json s3://datalake-pipeline-landing-dev/

# Aguardar Lambda processar (60s)
sleep 60

# Arquivo 2: MESMO carChassis, mileage=8500 (maior)
aws s3 cp test_data/car_silver_data_v1.json s3://datalake-pipeline-landing-dev/

sleep 60
```

### Passo 2: Executar Glue Job

```bash
aws glue start-job-run --job-name datalake-pipeline-silver-consolidation-dev
```

### Passo 3: Executar Crawler

```bash
aws glue start-crawler --name datalake-pipeline-silver-crawler-dev
```

### Passo 4: Validar no Athena

```sql
-- Verificar duplicatas (esperado: 0 linhas)
SELECT carChassis, event_day, COUNT(*) as count
FROM silver_car_telemetry
GROUP BY carChassis, event_day
HAVING COUNT(*) > 1;

-- Verificar registro consolidado (esperado: mileage=8500)
SELECT carChassis, currentMileage
FROM silver_car_telemetry
WHERE event_year = '2025' AND event_month = '10' AND event_day = '29';
```

**Resultado esperado:**
- ‚úÖ 0 duplicatas
- ‚úÖ Apenas registro com `currentMileage = 8500` (maior milhagem)

---

## ‚öôÔ∏è Configura√ß√µes

### Vari√°veis Terraform Principais

| Vari√°vel | Valor Padr√£o | Descri√ß√£o |
|----------|--------------|-----------|
| `glue_version` | `4.0` | Spark 3.3, Python 3 |
| `glue_worker_type` | `G.1X` | 4 vCPU, 16 GB RAM |
| `glue_number_of_workers` | `2` | N√∫mero de workers |
| `glue_trigger_schedule` | `cron(0 */1 * * ? *)` | Hor√°rio |
| `glue_trigger_enabled` | `true` | Trigger habilitado |
| `glue_job_timeout_minutes` | `60` | Timeout 1 hora |
| `bronze_table_name` | `bronze_ingest_year_2025` | Tabela Bronze |
| `silver_table_name` | `silver_car_telemetry` | Tabela Silver |
| `cloudwatch_log_retention_days` | `14` | Reten√ß√£o logs |

### Customiza√ß√£o de Frequ√™ncia

```bash
# Alterar para 2√ó/dia
terraform apply -var="glue_trigger_schedule=cron(0 0,12 * * ? *)"

# Alterar para di√°rio √†s 2 AM UTC
terraform apply -var="glue_trigger_schedule=cron(0 2 * * ? *)"

# Desabilitar trigger
terraform apply -var="glue_trigger_enabled=false"
```

---

## üí∞ Custos

### Configura√ß√£o Padr√£o

| Componente | Custo Mensal (us-east-1) |
|------------|--------------------------|
| Glue Job (hor√°rio, 2√óG.1X, 5min) | $52,80 |
| S3 Scripts | $0,01 |
| S3 Temp | $0,10 |
| CloudWatch Logs | $0,50 |
| **TOTAL** | **~$53,50/m√™s** |

### Otimiza√ß√µes

| Mudan√ßa | Novo Custo | Economia |
|---------|------------|----------|
| Reduzir para 2√ó/dia | $4,40 | 92% |
| Usar G.025X | $26,40 | 50% |
| 1 worker | $26,40 | 50% |

**Compara√ß√£o com Lambda:**
- Lambda (antigo): $1,50/m√™s ‚ùå Com duplicatas
- Glue Job (novo): $53,50/m√™s ‚úÖ Sem duplicatas + consolida√ß√£o

---

## üìä Monitoramento

### CloudWatch Logs

```bash
# Tempo real
aws logs tail /aws-glue/jobs/datalake-pipeline-silver-consolidation-dev --follow

# √öltimas 2 horas
aws logs tail /aws-glue/jobs/datalake-pipeline-silver-consolidation-dev --since 2h

# Filtrar erros
aws logs tail /aws-glue/jobs/datalake-pipeline-silver-consolidation-dev --filter-pattern "ERROR"
```

### M√©tricas

- **Console AWS:** CloudWatch ‚Üí Metrics ‚Üí Glue ‚Üí JobName
- **M√©tricas importantes:**
  - `glue.driver.aggregate.numCompletedStages`
  - `glue.ALL.s3.filesystem.read_bytes`
  - `glue.ALL.s3.filesystem.write_bytes`

### Job Bookmarks

```bash
# Verificar progresso
aws glue get-job-bookmark --job-name datalake-pipeline-silver-consolidation-dev
```

---

## üîß Manuten√ß√£o

### Atualizar Script PySpark

```bash
# 1. Editar script
vim ../glue_jobs/silver_consolidation_job.py

# 2. Terraform detecta mudan√ßa automaticamente
terraform apply
```

### Ajustar Capacidade

```bash
# Aumentar workers
terraform apply -var="glue_number_of_workers=5"

# Usar worker mais potente
terraform apply -var="glue_worker_type=G.2X"
```

### Reset Job Bookmarks

```bash
# Reprocessar todos os dados
aws glue reset-job-bookmark --job-name datalake-pipeline-silver-consolidation-dev
```

---

## üÜò Troubleshooting

### Job n√£o inicia

```bash
# Verificar trigger
aws glue get-trigger --name datalake-pipeline-silver-consolidation-trigger-dev \
  --query 'Trigger.State'

# Iniciar manualmente
aws glue start-trigger --name datalake-pipeline-silver-consolidation-trigger-dev
```

### Erro de permiss√£o S3

```bash
# Verificar pol√≠ticas IAM
terraform state show aws_iam_role_policy.glue_s3_access

# Recriar se necess√°rio
terraform taint aws_iam_role_policy.glue_s3_access
terraform apply
```

### Dados duplicados (bookmarks n√£o funcionam)

```bash
# Verificar argumento do Job
aws glue get-job --job-name datalake-pipeline-silver-consolidation-dev \
  --query 'Job.DefaultArguments."--job-bookmark-option"'

# Deve retornar: "job-bookmark-enable"
```

---

## üîÑ Rollback

### Rollback Completo

```bash
# 1. Desabilitar trigger
terraform apply -var="glue_trigger_enabled=false"

# 2. Destruir recursos
terraform destroy -target=aws_glue_job.silver_consolidation
terraform destroy -target=aws_iam_role.glue_job

# 3. Restaurar Lambda trigger (se necess√°rio)
# Descomentar c√≥digo em lambda.tf
terraform apply
```

### Rollback via Backup

```bash
# Restaurar estado Terraform
Copy-Item terraform-backups\terraform-state-YYYYMMDD_HHMMSS.tfstate terraform.tfstate -Force
terraform apply
```

---

## üìö Documenta√ß√£o Completa

| Documento | Descri√ß√£o |
|-----------|-----------|
| [GLUE_JOB_SILVER_CONSOLIDATION.md](../docs/GLUE_JOB_SILVER_CONSOLIDATION.md) | Explica√ß√£o detalhada do script PySpark |
| [MIGRATION_LAMBDA_TO_GLUE.md](../docs/MIGRATION_LAMBDA_TO_GLUE.md) | Guia completo de migra√ß√£o |
| [ARCHITECTURE_DIAGRAM.md](../docs/ARCHITECTURE_DIAGRAM.md) | Diagramas da arquitetura |
| [COMMANDS_CHEATSHEET.md](../docs/COMMANDS_CHEATSHEET.md) | Comandos √∫teis (cheatsheet) |
| [SUMMARY_GLUE_MIGRATION.md](../docs/SUMMARY_GLUE_MIGRATION.md) | Resumo executivo |
| [README_GLUE_TERRAFORM.md](README_GLUE_TERRAFORM.md) | Manual da infraestrutura Terraform |

---

## ‚úÖ Checklist de Deploy

- [ ] Terraform instalado (>= 1.0)
- [ ] AWS CLI configurado
- [ ] Credenciais AWS v√°lidas
- [ ] Script PySpark validado
- [ ] Backup do estado Terraform
- [ ] `terraform init` executado
- [ ] `terraform plan` revisado
- [ ] `terraform apply` confirmado
- [ ] Recursos validados (Glue Job, Trigger, Script S3)
- [ ] Teste manual executado
- [ ] Logs monitorados
- [ ] Dados de teste processados
- [ ] Deduplica√ß√£o validada no Athena
- [ ] Custos monitorados (AWS Cost Explorer)

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Aplicar Terraform** (`.\deploy_glue_migration.ps1`)
2. ‚úÖ **Validar recursos** criados
3. ‚úÖ **Executar teste manual** do Glue Job
4. ‚úÖ **Upload dados de teste** e validar deduplica√ß√£o
5. ‚è≥ **Monitorar execu√ß√µes agendadas** (1 semana)
6. ‚è≥ **Otimizar custos** (ajustar frequ√™ncia/workers)
7. ‚è≥ **(Opcional) Remover Lambda Cleansing** ap√≥s valida√ß√£o

---

## üìû Suporte

**Em caso de problemas:**

1. Verificar logs: `aws logs tail /aws-glue/jobs/... --follow`
2. Verificar estado: `aws glue get-job-runs --job-name ... --max-results 1`
3. Consultar documenta√ß√£o: `docs/`
4. Rollback se necess√°rio: restaurar backup Terraform

---

## üìù Notas Importantes

- ‚ö†Ô∏è **Job Bookmarks:** N√ÉO delete arquivos Bronze durante processamento
- ‚ö†Ô∏è **Dynamic Overwrite:** Sobrescreve apenas parti√ß√µes afetadas (eficiente)
- ‚ö†Ô∏è **Deduplica√ß√£o:** Chave = `carChassis + event_date`, Regra = `currentMileage DESC`
- ‚ö†Ô∏è **Custos:** Glue Job mais caro que Lambda, mas resolve duplicatas
- ‚ö†Ô∏è **Logs:** Retidos por 14 dias (configur√°vel)

---

## üèÜ Status do Projeto

| Componente | Status | Observa√ß√µes |
|------------|--------|-------------|
| **Script PySpark** | ‚úÖ Completo | 370+ linhas, l√≥gica de Upsert |
| **Infraestrutura Terraform** | ‚úÖ Completo | 11 recursos, 400+ linhas |
| **Documenta√ß√£o** | ‚úÖ Completo | 3.270+ linhas |
| **Script de Deploy** | ‚úÖ Completo | Automa√ß√£o com valida√ß√µes |
| **Testes Unit√°rios** | ‚è≥ Pendente | Aguardando deploy |
| **Valida√ß√£o E2E** | ‚è≥ Pendente | Aguardando deploy |

---

## üéâ PRONTO PARA PRODU√á√ÉO!

Execute:
```powershell
cd terraform
.\deploy_glue_migration.ps1
```

---

**Autor:** Sistema de Data Lakehouse  
**Data:** 2025-10-30  
**Vers√£o:** 1.0  
**Licen√ßa:** Propriet√°rio  

**üöÄ Bom Deploy!**
