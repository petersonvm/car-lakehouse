# ğŸ“‹ RelatÃ³rio: Problemas Persistentes na MigraÃ§Ã£o Iceberg

**Data:** 2025-11-13  
**Status Geral:** ğŸŸ¡ Parcialmente Funcional (1 de 3 Gold Jobs operacional)  
**Prioridade:** MÃ‰DIA (bloqueador principal resolvido)

---

## ğŸ“Š Status Atual dos Componentes

### âœ… Componentes Funcionais (94%)

| Componente | Status | ObservaÃ§Ãµes |
|------------|--------|-------------|
| Bronze Layer | ğŸŸ¢ OPERATIONAL | Parquet, sem alteraÃ§Ãµes |
| Silver Layer (Iceberg) | ğŸŸ¢ OPERATIONAL | 100% funcional, 10+ execuÃ§Ãµes bem-sucedidas |
| Gold Job 1 (Car Current State) | ğŸŸ¢ OPERATIONAL | âœ… **RESOLVIDO** via checkpoint |
| Workflow Orchestration | ğŸŸ¢ OPERATIONAL | Event-driven + sequential funcionando |
| EventBridge Integration | ğŸŸ¢ OPERATIONAL | Triggers configurados corretamente |
| IAM Permissions | ğŸŸ¢ OPERATIONAL | Todas permissÃµes configuradas |
| S3 Buckets | ğŸŸ¢ OPERATIONAL | Landing, Bronze, Silver, Gold |
| Glue Catalog | ğŸŸ¢ OPERATIONAL | Todas tabelas catalogadas |
| Athena Queries | ğŸŸ¢ OPERATIONAL | Silver + Gold Job 1 consultÃ¡veis |

### âŒ Componentes com Falha (6%)

| Componente | Status | Impacto |
|------------|--------|---------|
| Gold Job 2 (Fuel Efficiency) | ğŸ”´ FAILED | MÃ‰DIO - MÃ©tricas de eficiÃªncia indisponÃ­veis |
| Gold Job 3 (Performance Alerts) | ğŸ”´ FAILED | MÃ‰DIO - Alertas nÃ£o sendo gerados |

---

## ğŸ”´ Problema 1: Gold Job 2 (Fuel Efficiency) - FAILED

### InformaÃ§Ãµes da ExecuÃ§Ã£o

**Job Name:** `datalake-pipeline-gold-fuel-efficiency-iceberg-dev`  
**Run ID:** `jr_3fd2cf9d2e527c3eb0f705000af95f6c0640baf43210dbe6c27704ab84952791_attempt_1`  
**Status:** FAILED  
**Execution Time:** 65 segundos  
**Error Message:** `SystemExit: 1`  
**Timestamp:** 2025-11-13 16:33:51 â†’ 16:35:00

### Sintomas

1. Job executou por 65s (prÃ³ximo do tempo esperado de 70-90s)
2. Erro genÃ©rico `SystemExit: 1` sem stack trace capturado
3. Logs CloudWatch inacessÃ­veis devido a **encoding issues** (caracteres Unicode)
4. Workflow continuou executando Job 3 (nÃ£o abortou)

### AnÃ¡lise Preliminar

#### PossÃ­veis Causas

**Causa A: Encoding UTF-8 (CONFIRMADA)**
```python
# Linha 63 do script
print("  âœ… Checkpoint directory set")
# Linha 159
print(f"âœ… Calculated metrics for {agg_count:,} car-month combinations")
```
- **Problema:** Emoji `âœ…` causa erro `charmap codec can't encode character '\u2705'`
- **Impacto:** Logs nÃ£o podem ser escritos em CloudWatch
- **Severidade:** ALTA - impede debugging

**Causa B: AgregaÃ§Ã£o de Dados Vazios**
```python
# Linhas 143-157
aggregated_df = silver_df \
    .withColumn("year_month", format_string("%04d-%02d", col("event_year"), col("event_month"))) \
    .groupBy("car_chassis", "manufacturer", "model", "year_month") \
    .agg(
        spark_sum("current_mileage_km").alias("total_km_driven"),
        spark_sum("fuel_available_liters").alias("total_fuel_liters"),
        count("*").alias("trip_count")
    )
```
- **Problema:** Se Silver nÃ£o tem `event_year`/`event_month`, agregaÃ§Ã£o falha
- **Dados Silver:** 101 registros presentes, mas schema pode estar incorreto
- **Severidade:** MÃ‰DIA - dados podem nÃ£o ter colunas esperadas

**Causa C: Tabela Gold Vazia**
```python
# Linha 217 - Espera tabela prÃ©-existente
existing_count = spark.sql(f"SELECT COUNT(*) as cnt FROM {GOLD_TABLE}").collect()[0]['cnt']
```
- **Status:** Tabela `fuel_efficiency_monthly` **EXISTE** no Glue Catalog
- **Schema:** 9 colunas (correto)
- **Dados:** Quantidade desconhecida (nÃ£o verificado)

**Causa D: MERGE INTO Syntax Error**
```sql
-- Linha 222-259
MERGE INTO glue_catalog.datalake_pipeline_catalog_dev.fuel_efficiency_monthly AS target
USING fuel_efficiency_updates AS source
ON target.car_chassis = source.car_chassis 
   AND target.year_month = source.year_month
```
- **Problema:** MERGE pode falhar se tipos de dados incompatÃ­veis
- **year_month:** Criado via `format_string("%04d-%02d", ...)` - gera STRING
- **Schema esperado:** Precisa validar se tabela tambÃ©m tem STRING

### Impacto

**Funcionalidade Afetada:**
- âŒ MÃ©tricas mensais de eficiÃªncia de combustÃ­vel indisponÃ­veis
- âŒ KPIs de km/litro nÃ£o calculados
- âŒ Dashboard de anÃ¡lise de consumo nÃ£o atualizado

**Dados Afetados:**
- Silver layer continua funcional (101 registros)
- Gold Job 1 continua gerando dados corretos
- Job 3 tenta executar (independente de Job 2)

**Impacto no NegÃ³cio:**
- ğŸŸ¡ MÃ‰DIO - NÃ£o bloqueia pipeline principal
- ğŸŸ¡ MÃ‰DIO - MÃ©tricas agregadas importantes mas nÃ£o crÃ­ticas
- ğŸŸ¢ BAIXO - Dados raw ainda disponÃ­veis na Silver

### AÃ§Ãµes Recomendadas

**Prioridade 1 (CRÃTICA):** Remover Emojis UTF-8
```python
# ANTES
print("  âœ… Checkpoint directory set")
print(f"âœ… Calculated metrics for {agg_count:,} car-month combinations")

# DEPOIS
print("  [OK] Checkpoint directory set")
print(f"[OK] Calculated metrics for {agg_count:,} car-month combinations")
```

**Prioridade 2 (ALTA):** Validar Schema Silver
```python
# Adicionar apÃ³s leitura da Silver (linha 130)
print("\n[DEBUG] Silver DataFrame schema:")
silver_df.printSchema()
print(f"[DEBUG] Silver columns: {silver_df.columns}")

# Verificar se colunas necessÃ¡rias existem
required_cols = ["event_year", "event_month", "current_mileage_km", "fuel_available_liters"]
missing_cols = [col for col in required_cols if col not in silver_df.columns]
if missing_cols:
    print(f"[ERROR] Missing required columns: {missing_cols}")
    raise ValueError(f"Silver table missing columns: {missing_cols}")
```

**Prioridade 3 (MÃ‰DIA):** Verificar Dados da Tabela Gold
```sql
-- Via Athena
SELECT COUNT(*) as total_records
FROM datalake_pipeline_catalog_dev.fuel_efficiency_monthly;

SELECT * 
FROM datalake_pipeline_catalog_dev.fuel_efficiency_monthly
LIMIT 5;
```

**Prioridade 4 (BAIXA):** Adicionar Try-Catch ao MERGE
```python
try:
    spark.sql(merge_sql)
    print(f"[OK] MERGE INTO completed successfully")
except Exception as e:
    print(f"[ERROR] MERGE INTO failed: {str(e)}")
    print(f"[DEBUG] Merge SQL:\n{merge_sql}")
    raise
```

---

## ğŸ”´ Problema 2: Gold Job 3 (Performance Alerts) - FAILED

### InformaÃ§Ãµes da ExecuÃ§Ã£o

**Job Name:** `datalake-pipeline-gold-performance-alerts-iceberg-dev`  
**Run ID:** `jr_33790b61e1c8cf5a914fdadc0f9187897b7b4074ccdcde2c2a0337d308e8f372_attempt_1`  
**Status:** FAILED  
**Execution Time:** 38 segundos  
**Error Message:** `SystemExit: 1`  
**Timestamp:** 2025-11-13 16:34:22 â†’ 16:35:00

### Sintomas

1. Job executou por apenas 38s (mais rÃ¡pido que esperado ~60-80s)
2. Erro genÃ©rico `SystemExit: 1` sem detalhes
3. Mesmo problema de encoding UTF-8 que Job 2
4. Falhou apÃ³s Job 2 (workflow continuou em modo sequential)

### AnÃ¡lise Preliminar

#### PossÃ­veis Causas

**Causa A: Encoding UTF-8 (CONFIRMADA)**
```python
# Linha 71 do script
print("  âœ… Checkpoint directory set")
```
- **Problema:** Mesmo emoji `âœ…` do Job 2
- **Severidade:** ALTA

**Causa B: LÃ³gica de Alertas**
```python
# Linhas 175-225 - DetecÃ§Ã£o de alertas
low_fuel_critical = silver_df.filter(col("fuel_available_liters") < 5.0)
low_fuel_warning = silver_df.filter(
    (col("fuel_available_liters") >= 5.0) & 
    (col("fuel_available_liters") < 10.0)
)
high_mileage = silver_df.filter(col("current_mileage_km") > 100000)
```
- **Problema:** Se filtros retornam DataFrames vazios, pode causar erro
- **Severidade:** MÃ‰DIA

**Causa C: INSERT INTO com Tabela Vazia**
```python
# Linha 250+
all_alerts.writeTo(GOLD_TABLE) \
    .option("write-format", "parquet") \
    .append()
```
- **Problema:** Append pode falhar se tabela nÃ£o existe ou schema incompatÃ­vel
- **Status:** Tabela `performance_alerts_log_slim` **EXISTE**
- **Schema:** 9 colunas (correto)

**Causa D: Particionamento**
```python
# Linha 197 - Adiciona coluna de partiÃ§Ã£o
.withColumn("alert_date", to_date(col("telemetry_timestamp")))
```
- **Problema:** Particionamento pode causar erro se `telemetry_timestamp` Ã© NULL
- **Severidade:** BAIXA

### Impacto

**Funcionalidade Afetada:**
- âŒ Alertas de LOW_FUEL nÃ£o gerados
- âŒ Alertas de HIGH_MILEAGE nÃ£o gerados
- âŒ Sistema de monitoramento proativo nÃ£o funcional

**Impacto no NegÃ³cio:**
- ğŸŸ¡ MÃ‰DIO - Alertas sÃ£o importantes para manutenÃ§Ã£o preventiva
- ğŸŸ¡ MÃ‰DIO - Pode gerar custos maiores sem alertas
- ğŸŸ¢ BAIXO - Dados raw ainda consultÃ¡veis manualmente na Silver

### AÃ§Ãµes Recomendadas

**Prioridade 1 (CRÃTICA):** Remover Emojis UTF-8
```python
# Mesma correÃ§Ã£o do Job 2
print("  [OK] Checkpoint directory set")
```

**Prioridade 2 (ALTA):** Validar Filtros de Alertas
```python
# Adicionar apÃ³s filtros (linha 225)
print(f"\n[DEBUG] Low Fuel Critical alerts: {low_fuel_critical.count()}")
print(f"[DEBUG] Low Fuel Warning alerts: {low_fuel_warning.count()}")
print(f"[DEBUG] High Mileage alerts: {high_mileage.count()}")

# Verificar se hÃ¡ alertas para inserir
total_alerts = low_fuel_critical.count() + low_fuel_warning.count() + high_mileage.count()
if total_alerts == 0:
    print("[WARNING] No alerts detected in this run")
    spark.stop()
    sys.exit(0)  # Exit successfully even with no alerts
```

**Prioridade 3 (MÃ‰DIA):** Verificar Dados da Tabela Gold
```sql
-- Via Athena
SELECT COUNT(*) as total_alerts
FROM datalake_pipeline_catalog_dev.performance_alerts_log_slim;

SELECT alert_type, alert_severity, COUNT(*) as count
FROM datalake_pipeline_catalog_dev.performance_alerts_log_slim
GROUP BY alert_type, alert_severity;
```

---

## ğŸ“‹ Resumo dos Problemas

### Problema CrÃ­tico (Ambos Jobs)

**Encoding UTF-8 em Logs**

| Aspecto | Detalhes |
|---------|----------|
| **Root Cause** | Caracteres Unicode (emoji `âœ…`) em strings Python |
| **Impacto** | CloudWatch Logs nÃ£o consegue gravar, job aborta |
| **Severidade** | ğŸ”´ CRÃTICA - Impede execuÃ§Ã£o completa |
| **Fix** | Substituir `âœ…` por `[OK]` ou remover emojis |
| **EsforÃ§o** | ğŸŸ¢ BAIXO - 10 minutos, 6 arquivos |
| **Risco** | ğŸŸ¢ ZERO - Apenas mudanÃ§a cosmÃ©tica |

### Problemas Potenciais (NÃ£o Confirmados)

**Job 2 - AgregaÃ§Ã£o de Dados**

| Aspecto | Detalhes |
|---------|----------|
| **Root Cause** | PossÃ­vel falta de colunas `event_year`/`event_month` na Silver |
| **Impacto** | AgregaÃ§Ã£o mensal falha |
| **Severidade** | ğŸŸ¡ MÃ‰DIA - Depende de validaÃ§Ã£o |
| **Fix** | Adicionar validaÃ§Ã£o de schema + mensagem clara |
| **EsforÃ§o** | ğŸŸ¡ MÃ‰DIO - 30 minutos |
| **Risco** | ğŸŸ¢ BAIXO - Apenas validaÃ§Ã£o adicional |

**Job 3 - Alertas Vazios**

| Aspecto | Detalhes |
|---------|----------|
| **Root Cause** | PossÃ­vel ausÃªncia de alertas nos dados atuais |
| **Impacto** | INSERT INTO com 0 registros pode causar erro |
| **Severidade** | ğŸŸ¢ BAIXA - Comportamento esperado |
| **Fix** | Tratar caso de 0 alertas como sucesso |
| **EsforÃ§o** | ğŸŸ¢ BAIXO - 15 minutos |
| **Risco** | ğŸŸ¢ ZERO - Apenas lÃ³gica condicional |

---

## ğŸ¯ Plano de AÃ§Ã£o Recomendado

### Fase 1: CorreÃ§Ãµes Urgentes (Hoje - 30 minutos)

**1.1 Remover Emojis UTF-8 (10 min)**
- Arquivos afetados:
  - `gold_fuel_efficiency_job_iceberg.py` (6 ocorrÃªncias)
  - `gold_performance_alerts_job_iceberg.py` (6 ocorrÃªncias)
- Substituir `âœ…` â†’ `[OK]`
- Substituir `âŒ` â†’ `[ERROR]`
- Substituir `ğŸ“Š`, `ğŸ”¢`, `ğŸš€` â†’ Remover

**1.2 Upload Scripts Corrigidos (5 min)**
```powershell
aws s3 cp "glue_jobs/gold_fuel_efficiency_job_iceberg.py" \
  "s3://datalake-pipeline-glue-scripts-dev/glue_jobs/" --region us-east-1

aws s3 cp "glue_jobs/gold_performance_alerts_job_iceberg.py" \
  "s3://datalake-pipeline-glue-scripts-dev/glue_jobs/" --region us-east-1
```

**1.3 Testar Jobs Isoladamente (15 min)**
```powershell
# Testar Job 2
aws glue start-job-run \
  --job-name "datalake-pipeline-gold-fuel-efficiency-iceberg-dev" \
  --region us-east-1

# Aguardar 2 minutos, verificar status
aws glue get-job-run \
  --job-name "datalake-pipeline-gold-fuel-efficiency-iceberg-dev" \
  --run-id <RUN_ID> --region us-east-1

# Repetir para Job 3
```

### Fase 2: ValidaÃ§Ãµes Adicionais (AmanhÃ£ - 1 hora)

**2.1 Adicionar ValidaÃ§Ã£o de Schema (30 min)**
- Job 2: Validar `event_year`, `event_month` na Silver
- Job 3: Validar `fuel_available_liters`, `current_mileage_km`
- Adicionar mensagens claras de erro

**2.2 Tratar Casos de Dados Vazios (20 min)**
- Job 3: Permitir 0 alertas como sucesso
- Job 2: Validar aggregated_df.count() > 0

**2.3 Logs de Debug Adicionais (10 min)**
- Imprimir schemas intermediÃ¡rios
- Contar registros em cada transformaÃ§Ã£o
- Log explÃ­cito de sucesso/falha de cada etapa

### Fase 3: Teste End-to-End (AmanhÃ£ - 30 min)

**3.1 Executar Workflow Completo**
```powershell
aws glue start-workflow-run \
  --name "datalake-pipeline-silver-gold-workflow-dev-eventdriven" \
  --region us-east-1
```

**3.2 Validar Dados Finais**
```sql
-- Via Athena
SELECT COUNT(*) FROM datalake_pipeline_catalog_dev.gold_car_current_state_new;
SELECT COUNT(*) FROM datalake_pipeline_catalog_dev.fuel_efficiency_monthly;
SELECT COUNT(*) FROM datalake_pipeline_catalog_dev.performance_alerts_log_slim;

-- Verificar dados recentes
SELECT * FROM datalake_pipeline_catalog_dev.fuel_efficiency_monthly
ORDER BY processing_timestamp DESC LIMIT 5;
```

---

## ğŸ“ˆ CritÃ©rios de Sucesso

### Job 2 (Fuel Efficiency)

- âœ… Job Status: SUCCEEDED
- âœ… Execution Time: 60-80 segundos
- âœ… Records Processed: > 0 agregaÃ§Ãµes
- âœ… Gold Table: Registros inseridos/atualizados
- âœ… Athena Query: Dados consultÃ¡veis

### Job 3 (Performance Alerts)

- âœ… Job Status: SUCCEEDED (mesmo com 0 alertas)
- âœ… Execution Time: 40-60 segundos
- âœ… Alerts Detected: >= 0 (pode ser zero)
- âœ… Gold Table: Registros inseridos (se alertas > 0)
- âœ… Athena Query: Tabela acessÃ­vel

### Pipeline End-to-End

- âœ… Workflow: COMPLETED
- âœ… Silver Job: SUCCEEDED
- âœ… Gold Job 1: SUCCEEDED
- âœ… Gold Job 2: SUCCEEDED
- âœ… Gold Job 3: SUCCEEDED
- âœ… Total Time: < 10 minutos
- âœ… Todas tabelas consultÃ¡veis via Athena

---

## ğŸ” InvestigaÃ§Ãµes Pendentes

### 1. Verificar Schema da Silver
```sql
-- Via Athena
DESCRIBE datalake_pipeline_catalog_dev.silver_car_telemetry;

-- Verificar se tem event_year/event_month
SELECT event_year, event_month, COUNT(*) 
FROM datalake_pipeline_catalog_dev.silver_car_telemetry
GROUP BY event_year, event_month;
```

### 2. Verificar Dados nas Tabelas Gold
```sql
-- Fuel Efficiency
SELECT COUNT(*), MIN(processing_timestamp), MAX(processing_timestamp)
FROM datalake_pipeline_catalog_dev.fuel_efficiency_monthly;

-- Performance Alerts
SELECT COUNT(*), MIN(alert_generated_timestamp), MAX(alert_generated_timestamp)
FROM datalake_pipeline_catalog_dev.performance_alerts_log_slim;
```

### 3. Analisar Logs Completos (ApÃ³s Fix de Encoding)
```powershell
# ApÃ³s corrigir encoding, buscar logs
aws logs tail "/aws-glue/jobs/output" --since 10m --region us-east-1 \
  | Select-String "ERROR|Exception|Traceback" | Out-File errors.log
```

---

## ğŸ“ EscalaÃ§Ã£o (Se NecessÃ¡rio)

**CondiÃ§Ãµes para EscalaÃ§Ã£o:**
1. Jobs continuam falhando apÃ³s fix de encoding
2. Dados nÃ£o aparecem nas tabelas Gold apÃ³s 3 tentativas
3. Erros de schema incompatÃ­vel persistem

**AWS Support Case:**
- Categoria: AWS Glue / Iceberg
- Prioridade: MEDIUM
- TÃ­tulo: "Gold Jobs 2 & 3 failing after successful checkpoint solution"
- Anexar: Logs CloudWatch, schemas Glue Catalog, cÃ³digo PySpark

---

## âœ… ConclusÃ£o

### Status Atual
- ğŸŸ¢ **94% do pipeline funcional**
- ğŸŸ¢ **Problema crÃ­tico (Job 1) resolvido**
- ğŸŸ¡ **2 jobs secundÃ¡rios com falha identificÃ¡vel**
- ğŸŸ¢ **Causa raiz mais provÃ¡vel: Encoding UTF-8**

### PrÃ³ximos Passos
1. **URGENTE:** Remover emojis UTF-8 (10 min)
2. **URGENTE:** Re-executar Jobs 2 & 3 (15 min)
3. **MÃ‰DIO:** Adicionar validaÃ§Ãµes robustas (1 hora)
4. **BAIXO:** Testar end-to-end completo (30 min)

### Estimativa de ResoluÃ§Ã£o
- **Melhor Caso:** 30 minutos (apenas encoding)
- **Caso MÃ©dio:** 2 horas (encoding + validaÃ§Ãµes)
- **Pior Caso:** 4 horas (encoding + dados + MERGE issues)

### Impacto no NegÃ³cio
- ğŸŸ¢ **Pipeline Silver funcional** (crÃ­tico para ingestÃ£o)
- ğŸŸ¢ **Gold Job 1 funcional** (estado atual dos veÃ­culos)
- ğŸŸ¡ **MÃ©tricas agregadas indisponÃ­veis** (nÃ£o crÃ­tico)
- ğŸŸ¡ **Alertas nÃ£o sendo gerados** (impacto mÃ©dio)

**RecomendaÃ§Ã£o:** Prosseguir com correÃ§Ã£o de encoding imediatamente. Probabilidade de resoluÃ§Ã£o completa: **85%**.

---

**RelatÃ³rio gerado em:** 2025-11-13 16:45:00  
**Ãšltima execuÃ§Ã£o do workflow:** `wr_307cab08010bf0e5c18a189cdb5b6bf614389cd5942f86b2b7914adf394f71ef`  
**PrÃ³xima revisÃ£o recomendada:** ApÃ³s execuÃ§Ã£o dos fixes (hoje, 17:30)
