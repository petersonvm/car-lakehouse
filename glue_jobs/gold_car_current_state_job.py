"""
AWS Glue ETL Job - Gold Layer: Car Current State
=================================================

Objetivo:
- Ler dados consolidados da Camada Silver (hist√≥rico completo)
- Aplicar l√≥gica de "Estado Atual" (1 linha por car_chassis)
- Escrever snapshot no Gold Bucket (sobrescrita total)

L√≥gica de Neg√≥cio:
- Chave de neg√≥cio: car_chassis
- Regra de sele√ß√£o: current_mileage_km DESC (o maior = mais recente)
- Resultado: 1 registro √∫nico por ve√≠culo (estado atual)

Caracter√≠sticas:
- Leitura: Tabela Silver completa (sem particionamento)
- Transforma√ß√£o: Window Function (row_number)
- Escrita: Overwrite completo (snapshot est√°tico)
- Sa√≠da: Parquet n√£o-particionado (tabela pequena)

Autor: Sistema de Data Lakehouse - Camada Gold
Data: 2025-10-30
"""

import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

from pyspark.sql import functions as F
from pyspark.sql.window import Window
from pyspark.sql.functions import col, to_date, current_date, datediff, when, lit
from datetime import datetime

# ============================================================================
# 1. INICIALIZA√á√ÉO DO JOB
# ============================================================================

print("\n" + "=" * 80)
print("ü•á AWS GLUE JOB - GOLD LAYER: CAR CURRENT STATE")
print("=" * 80)

# Obter par√¢metros do Job
args = getResolvedOptions(sys.argv, [
    'JOB_NAME',
    'silver_database',
    'silver_table',
    'gold_database',
    'gold_bucket',
    'gold_path'
])

print(f"\nüìã Par√¢metros do Job:")
print(f"   Job Name: {args['JOB_NAME']}")
print(f"   Silver Database: {args['silver_database']}")
print(f"   Silver Table: {args['silver_table']}")
print(f"   Gold Database: {args['gold_database']}")
print(f"   Gold Bucket: {args['gold_bucket']}")
print(f"   Gold Path: {args['gold_path']}")

# Inicializar contextos Spark e Glue
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

print("\n‚úÖ Contextos Spark e Glue inicializados com sucesso")

# ============================================================================
# 2. LEITURA DA CAMADA SILVER
# ============================================================================

print("\n" + "=" * 80)
print("üìö ETAPA 1: Lendo dados consolidados da Camada Silver")
print("=" * 80)

print(f"\n   Database: {args['silver_database']}")
print(f"   Table: {args['silver_table']}")

# Ler tabela Silver completa do Glue Data Catalog
silver_dynamic_frame = glueContext.create_dynamic_frame.from_catalog(
    database=args['silver_database'],
    table_name=args['silver_table'],
    transformation_ctx="silver_data"
)

# Converter para DataFrame
df_silver = silver_dynamic_frame.toDF()

# Contar registros totais
total_records = df_silver.count()
print(f"\n   ‚úÖ Registros lidos da Silver: {total_records}")

if total_records == 0:
    print("\n   ‚ö†Ô∏è  AVISO: Nenhum dado encontrado na Camada Silver!")
    print("   Finalizando job sem gerar dados no Gold.")
    job.commit()
    print("\n‚úÖ JOB CONCLU√çDO (sem dados para processar)")
    # N√£o usar sys.exit() - deixar completar naturalmente
else:
    print("\n   üìä Schema da Camada Silver:")
    df_silver.printSchema()

    # Mostrar amostra dos dados Silver
    print("\n   üìã Amostra de dados Silver (primeiros 5 registros):")
    df_silver.select(
        "car_chassis",
        "current_mileage_km",
        "telemetry_timestamp",
        "event_year",
        "event_month",
        "event_day"
    ).show(5, truncate=False)

    # ============================================================================
    # 3. TRANSFORMA√á√ÉO: ESTADO ATUAL (WINDOW FUNCTION)
    # ============================================================================

    print("\n" + "=" * 80)
    print("üîÑ ETAPA 2: Aplicando l√≥gica de 'Estado Atual'")
    print("=" * 80)

    print("\n   üéØ Regra de Neg√≥cio:")
    print("      - 1 registro por car_chassis (ve√≠culo)")
    print("      - Crit√©rio: MAIOR current_mileage_km (mais recente)")
    print("      - M√©todo: Window Function com row_number()")

    # Definir Window Specification
    # Particionar por: car_chassis (cada ve√≠culo)
    # Ordenar por: current_mileage_km DESC (maior milhagem = mais recente)
    window_spec = Window.partitionBy("car_chassis").orderBy(F.col("current_mileage_km").desc())

    print("\n   üîπ Aplicando Window Function...")

    # Adicionar coluna row_number
    df_with_row_number = df_silver.withColumn(
        "row_num",
        F.row_number().over(window_spec)
    )

    print("      ‚úÖ row_number() aplicado")

    # Filtrar apenas row_number = 1 (estado atual)
    df_current_state = df_with_row_number.filter(F.col("row_num") == 1).drop("row_num")

    current_state_count = df_current_state.count()
    vehicles_deduped = total_records - current_state_count

    print(f"\n   üìä Resultado da Transforma√ß√£o:")
    print(f"      - Registros hist√≥ricos (Silver): {total_records}")
    print(f"      - Registros de estado atual (Gold): {current_state_count}")
    print(f"      - Registros hist√≥ricos descartados: {vehicles_deduped}")
    print(f"      - Taxa de redu√ß√£o: {(vehicles_deduped / total_records * 100):.1f}%")

    # ============================================================================
    # 4. ENRIQUECIMENTO: KPIs DE SEGURO
    # ============================================================================

    print("\n" + "=" * 80)
    print("üõ°Ô∏è  ETAPA 3: Enriquecimento com KPIs de Seguro")
    print("=" * 80)

    print("\n   üéØ KPIs de Seguro a serem calculados:")
    print("      1. insurance_status (String): VENCIDO | VENCENDO_EM_90_DIAS | ATIVO")
    print("      2. insurance_days_expired (Int): Dias desde vencimento (null se ativo)")
    print("\n   üìä L√≥gica de Neg√≥cio:")
    print("      - Fonte: insurance_valid_until (campo achatado do Silver)")
    print("      - Refer√™ncia: current_date() no momento da execu√ß√£o")
    print("      - VENCIDO: validUntil < current_date")
    print("      - VENCENDO_EM_90_DIAS: 0 <= days_remaining <= 90")
    print("      - ATIVO: days_remaining > 90")

    print("\n   üîπ Aplicando transforma√ß√µes de data...")

    # Definir colunas de data
    current_date_col = current_date()
    # Campo achatado do Silver: insurance_valid_until (formato: "2026-10-29")
    valid_until_date_col = to_date(col("insurance_valid_until"), "yyyy-MM-dd")

    # Calcular diferen√ßa em dias
    # datediff(end_date, start_date) -> Positivo se end_date > start_date
    # Neste caso: datediff(validUntil, current_date)
    # - Positivo = dias restantes at√© vencer
    # - Negativo = dias vencidos
    days_diff_col = datediff(valid_until_date_col, current_date_col)

    print("      ‚úÖ Colunas de data configuradas")
    print("         - current_date: Data de execu√ß√£o do job")
    print("         - valid_until: insurance_valid_until convertido para date")
    print("         - days_diff: Diferen√ßa em dias (positivo = restantes, negativo = vencidos)")

    # Enriquecer DataFrame com KPIs de seguro
    df_enriched = df_current_state.withColumn(
        "insurance_status",
        when(days_diff_col < 0, "VENCIDO")
        .when((days_diff_col >= 0) & (days_diff_col <= 90), "VENCENDO_EM_90_DIAS")
        .otherwise("ATIVO")
    ).withColumn(
        "insurance_days_expired",
        when(days_diff_col < 0, -days_diff_col)  # Converte negativo em dias vencidos
        .otherwise(lit(None).cast("int"))         # Null se n√£o estiver vencido
    )

    print("      ‚úÖ KPIs de seguro adicionados")

    # Estat√≠sticas dos status de seguro
    print("\n   üìä Distribui√ß√£o de Status de Seguro:")
    insurance_stats = df_enriched.groupBy("insurance_status").count().orderBy(F.col("count").desc())
    insurance_stats.show(10, truncate=False)

    # Mostrar amostra com os novos campos
    print("\n   üìã Amostra de dados com KPIs de Seguro:")
    df_enriched.select(
        "car_chassis",
        "manufacturer",
        "model",
        "insurance_valid_until",
        "insurance_status",
        "insurance_days_expired"
    ).orderBy(F.col("current_mileage_km").desc()).show(5, truncate=False)

    # ============================================================================
    # 5. ENRIQUECIMENTO ADICIONAL (METADADOS GOLD)
    # ============================================================================

    print("\n" + "=" * 80)
    print("üîß ETAPA 4: Enriquecimento adicional da Camada Gold")
    print("=" * 80)

    # Adicionar timestamp de processamento (metadado Gold)
    df_gold = df_enriched.withColumn(
        "gold_processing_timestamp",
        F.current_timestamp()
    ).withColumn(
        "gold_snapshot_date",
        F.current_date()
    )

    print("   ‚úÖ Metadados Gold adicionados:")
    print("      - gold_processing_timestamp: timestamp da execu√ß√£o do job")
    print("      - gold_snapshot_date: data do snapshot")

    # Calcular m√©tricas agregadas (opcional - exemplo)
    print("\n   üìä Estat√≠sticas do Estado Atual:")
    
    # Contar ve√≠culos por fabricante
    manufacturer_stats = df_gold.groupBy("manufacturer").count().orderBy(F.col("count").desc())
    print("\n   üè≠ Ve√≠culos por Fabricante:")
    manufacturer_stats.show(10, truncate=False)

    # Mostrar amostra dos dados Gold finais
    print("\n   üìã Amostra de dados Gold (estado atual - primeiros 5 ve√≠culos):")
    df_gold.select(
        "car_chassis",
        "manufacturer",
        "model",
        "current_mileage_km",
        "telemetry_timestamp",
        "gold_processing_timestamp"
    ).orderBy(F.col("current_mileage_km").desc()).show(5, truncate=False)

    # ============================================================================
    # 6. ESCRITA NO GOLD BUCKET (OVERWRITE COMPLETO)
    # ============================================================================

    print("\n" + "=" * 80)
    print("üíæ ETAPA 5: Escrevendo dados no Gold Bucket")
    print("=" * 80)

    gold_output_path = f"s3://{args['gold_bucket']}/{args['gold_path']}"
    
    print(f"\n   üì¶ Configura√ß√£o de Escrita:")
    print(f"      - Bucket: {args['gold_bucket']}")
    print(f"      - Path: {args['gold_path']}")
    print(f"      - Full Path: {gold_output_path}")
    print(f"      - Modo: overwrite (snapshot completo)")
    print(f"      - Formato: parquet")
    print(f"      - Compress√£o: snappy")
    print(f"      - Particionamento: Nenhum (tabela pequena)")

    print("\n   üöÄ Iniciando escrita...")

    # Escrever dados usando Spark DataFrame Writer
    # Modo overwrite: sobrescreve todo o diret√≥rio (snapshot est√°tico)
    df_gold.write \
        .mode("overwrite") \
        .format("parquet") \
        .option("compression", "snappy") \
        .save(gold_output_path)

    print(f"\n   ‚úÖ Dados escritos com sucesso!")
    print(f"   üìä Total de registros no Gold: {current_state_count}")

    # Verificar arquivos escritos
    print("\n   üìÇ Arquivos Parquet gerados:")
    try:
        files_df = spark.read.parquet(gold_output_path)
        num_files = len([f for f in spark._jvm.org.apache.hadoop.fs.FileSystem.get(
            spark._jsc.hadoopConfiguration()
        ).listStatus(
            spark._jvm.org.apache.hadoop.fs.Path(gold_output_path)
        ) if f.getPath().getName().endswith(".parquet")])
        print(f"      - N√∫mero de arquivos: {num_files}")
        print(f"      - Total de registros: {files_df.count()}")
    except Exception as e:
        print(f"      ‚ö†Ô∏è  N√£o foi poss√≠vel listar arquivos: {e}")

    # ============================================================================
    # 7. FINALIZA√á√ÉO DO JOB
    # ============================================================================

    print("\n" + "=" * 80)
    print("‚úÖ JOB CONCLU√çDO COM SUCESSO!")
    print("=" * 80)
    
    print(f"\nüìä Resumo Final:")
    print(f"   - Registros lidos (Silver): {total_records}")
    print(f"   - Ve√≠culos √∫nicos (Gold): {current_state_count}")
    print(f"   - Redu√ß√£o de dados: {(vehicles_deduped / total_records * 100):.1f}%")
    print(f"   - KPIs adicionados: insurance_status, insurance_days_expired")
    print(f"   - Output Path: {gold_output_path}")
    print(f"   - Snapshot Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print("\nüìä Distribui√ß√£o Final de Status de Seguro:")
    final_insurance_stats = df_gold.groupBy("insurance_status").count().collect()
    for row in final_insurance_stats:
        print(f"   - {row['insurance_status']}: {row['count']} ve√≠culos")
    
    print("\n" + "=" * 80)
    print("üéØ Pr√≥ximos Passos:")
    print("   1. Workflow ir√° acionar Gold Crawler automaticamente")
    print("   2. Crawler atualizar√° tabela 'gold_car_current_state' no cat√°logo")
    print("   3. Dados estar√£o dispon√≠veis para consulta no Athena")
    print("   4. Novas colunas dispon√≠veis:")
    print("      - insurance_status: Status do seguro do ve√≠culo")
    print("      - insurance_days_expired: Dias vencidos (se aplic√°vel)")
    print("=" * 80)

    # Commit do Job
    job.commit()

    print("\n‚úÖ Job commit realizado com sucesso")