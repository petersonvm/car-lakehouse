# Infraestrutura AWS Glue para Camada Bronze - car_data

## ğŸ“‹ VisÃ£o Geral

Este documento descreve a infraestrutura Terraform criada para tornar os dados da **Camada Bronze** automaticamente detectÃ¡veis e consultÃ¡veis via **Amazon Athena**, utilizando **AWS Glue Crawlers**.

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS Glue Infrastructure                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Glue Catalog Database                                    â”‚  â”‚
â”‚  â”‚  â€¢ Name: datalake-pipeline-catalog-dev                   â”‚  â”‚
â”‚  â”‚  â€¢ Purpose: Central metadata repository                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â”‚ cataloged in                       â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Bronze Car Data Crawler                                 â”‚  â”‚
â”‚  â”‚  â€¢ Name: datalake-pipeline-bronze-car-data-crawler-dev   â”‚  â”‚
â”‚  â”‚  â€¢ Schedule: Daily at 00:00 UTC                         â”‚  â”‚
â”‚  â”‚  â€¢ Target: s3://bronze/car_data/                        â”‚  â”‚
â”‚  â”‚  â€¢ Table Prefix: bronze_                                â”‚  â”‚
â”‚  â”‚  â€¢ Features: Preserves nested structures (structs)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â”‚ discovers                          â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  S3 Bronze Data (Parquet with Structs)                  â”‚  â”‚
â”‚  â”‚  â€¢ Path: s3://bronze/car_data/                          â”‚  â”‚
â”‚  â”‚  â€¢ Partitioning: ingest_year/ingest_month/ingest_day    â”‚  â”‚
â”‚  â”‚  â€¢ Format: Parquet with nested structures               â”‚  â”‚
â”‚  â”‚  â€¢ Structs: metrics, market, carInsurance, owner        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â”‚ queryable via                      â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Amazon Athena                                           â”‚  â”‚
â”‚  â”‚  â€¢ Query Engine: Presto/Trino                           â”‚  â”‚
â”‚  â”‚  â€¢ Access: Dot notation for nested fields               â”‚  â”‚
â”‚  â”‚  â€¢ Example: metrics.engineTempCelsius                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Recursos Terraform Criados

### 1. IAM Role para Glue Crawler

**Recurso**: `aws_iam_role.glue_crawler_role`

```hcl
resource "aws_iam_role" "glue_crawler_role" {
  name               = "datalake-pipeline-glue-crawler-role-dev"
  description        = "IAM role for Glue Crawler to access S3 and Glue Catalog"
  assume_role_policy = data.aws_iam_policy_document.glue_assume_role.json
}
```

**PolÃ­ticas Anexadas**:
1. **S3 Access** (`aws_iam_role_policy.glue_s3_policy`):
   - `s3:GetObject` - Ler arquivos Parquet
   - `s3:ListBucket` - Listar diretÃ³rios particionados

2. **Glue Catalog Access** (`aws_iam_role_policy.glue_catalog_policy`):
   - `glue:GetDatabase`, `glue:GetTable` - Ler metadados
   - `glue:CreateTable`, `glue:UpdateTable` - Criar/atualizar tabelas
   - `glue:GetPartition`, `glue:CreatePartition` - Gerenciar partiÃ§Ãµes
   - `glue:BatchCreatePartition`, `glue:BatchUpdatePartition` - OperaÃ§Ãµes em lote

3. **CloudWatch Logs** (`aws_iam_role_policy.glue_cloudwatch_policy`):
   - `logs:CreateLogGroup`, `logs:CreateLogStream`, `logs:PutLogEvents`

### 2. Glue Catalog Database

**Recurso**: `aws_glue_catalog_database.data_lake_database`

```hcl
resource "aws_glue_catalog_database" "data_lake_database" {
  name        = "datalake-pipeline-catalog-dev"
  description = "Glue Data Catalog database for datalake-pipeline lakehouse architecture"
}
```

**PropÃ³sito**: RepositÃ³rio central de metadados para todas as tabelas (Bronze, Silver, Gold).

### 3. Bronze Car Data Crawler

**Recurso**: `aws_glue_crawler.bronze_car_data_crawler`

```hcl
resource "aws_glue_crawler" "bronze_car_data_crawler" {
  name          = "datalake-pipeline-bronze-car-data-crawler-dev"
  description   = "Crawler for Bronze layer car_data with nested structures (structs)"
  role          = aws_iam_role.glue_crawler_role.arn
  database_name = aws_glue_catalog_database.data_lake_database.name
  
  # Schedule - Daily at midnight UTC
  schedule = "cron(0 0 * * ? *)"
  
  # Target S3 path with HIVE-style partitioning
  s3_target {
    path = "s3://datalake-pipeline-bronze-dev/bronze/car_data/"
    
    exclusions = [
      "**/_temporary/**",
      "**/_SUCCESS",
      "**/.spark*"
    ]
  }
  
  # Table prefix
  table_prefix = "bronze_"
}
```

#### ConfiguraÃ§Ãµes CrÃ­ticas para Estruturas Aninhadas

**Schema Change Policy**:
```hcl
schema_change_policy {
  delete_behavior = "LOG"                    # Log deletions, don't remove tables
  update_behavior = "UPDATE_IN_DATABASE"     # Update schema when structs change
}
```

**Recrawl Policy**:
```hcl
recrawl_policy {
  recrawl_behavior = "CRAWL_EVERYTHING"  # Always check for schema changes
}
```

**Configuration** (JSON):
```json
{
  "Version": 1.0,
  "CrawlerOutput": {
    "Partitions": {
      "AddOrUpdateBehavior": "InheritFromTable"  // HIVE-style partitions
    },
    "Tables": {
      "AddOrUpdateBehavior": "MergeNewColumns"   // Add new struct fields
    }
  },
  "Grouping": {
    "TableGroupingPolicy": "CombineCompatibleSchemas"
  }
}
```

## ğŸ“Š Estrutura de Dados Bronze

### LocalizaÃ§Ã£o S3
```
s3://datalake-pipeline-bronze-dev/bronze/car_data/
â””â”€â”€ ingest_year=2025/
    â””â”€â”€ ingest_month=10/
        â””â”€â”€ ingest_day=30/
            â””â”€â”€ car_data_20251030_140345_73ca8a0e.parquet
```

### Schema da Tabela `bronze_car_data`

**Tabela Criada pelo Crawler**: `bronze_car_data`

#### Colunas Top-Level
| Column | Type | Description |
|--------|------|-------------|
| `carChassis` | string | Identificador Ãºnico do veÃ­culo |
| `manufacturer` | string | Fabricante do veÃ­culo |
| `model` | string | Modelo do veÃ­culo |
| `year` | int64 | Ano de fabricaÃ§Ã£o |
| `color` | string | Cor do veÃ­culo |
| `ingestion_timestamp` | string | Timestamp de ingestÃ£o (ISO 8601) |
| `source_file` | string | Nome do arquivo JSON original |
| `source_bucket` | string | Nome do bucket de origem |

#### Colunas Struct (Nested)

**1. `metrics` - struct<...>**
```sql
struct<
  engineTempCelsius: double,
  fuelCapacityLitres: double,
  fuelLevelLitres: double,
  metricTimestamp: string,
  odometerKm: double,
  speedKmh: double,
  tripDistanceKm: double
>
```

**2. `market` - struct<...>**
```sql
struct<
  currency: string,
  currentPrice: double,
  marketRegion: string,
  marketSegment: string
>
```

**3. `carInsurance` - struct<...>**
```sql
struct<
  annualPremium: double,
  coverageType: string,
  expiryDate: string,
  policyNumber: string,
  provider: string
>
```

**4. `owner` - struct<...>**
```sql
struct<
  contactEmail: string,
  ownerId: string,
  ownerName: string,
  ownershipStartDate: string
>
```

#### PartiÃ§Ãµes (Hive-Style)
| Partition Column | Type | Description |
|------------------|------|-------------|
| `ingest_year` | int | Ano da ingestÃ£o |
| `ingest_month` | int | MÃªs da ingestÃ£o (1-12) |
| `ingest_day` | int | Dia da ingestÃ£o (1-31) |

## ğŸš€ Deploy da Infraestrutura

### PrÃ©-requisitos
- Terraform instalado
- AWS CLI configurado
- PermissÃµes IAM adequadas

### Comandos de Deploy

```bash
# 1. Navegar para o diretÃ³rio Terraform
cd c:\dev\HP\wsas\Poc\terraform

# 2. Inicializar Terraform (se necessÃ¡rio)
terraform init

# 3. Validar configuraÃ§Ã£o
terraform validate

# 4. Planejar mudanÃ§as
terraform plan

# 5. Aplicar mudanÃ§as
terraform apply

# Ou aplicar apenas os recursos Glue
terraform apply -target="aws_glue_crawler.bronze_car_data_crawler"
```

### ValidaÃ§Ã£o do Deploy

```bash
# Verificar se o crawler foi criado
aws glue get-crawler --name datalake-pipeline-bronze-car-data-crawler-dev

# Listar crawlers
aws glue list-crawlers --query "CrawlerNames[?contains(@, 'bronze')]"
```

## ğŸ”„ Executando o Crawler

### ExecuÃ§Ã£o Manual

```bash
# Iniciar crawler manualmente
aws glue start-crawler --name datalake-pipeline-bronze-car-data-crawler-dev

# Verificar status do crawler
aws glue get-crawler --name datalake-pipeline-bronze-car-data-crawler-dev \
  --query "Crawler.State" --output text

# Acompanhar logs do crawler
aws glue get-crawler --name datalake-pipeline-bronze-car-data-crawler-dev \
  --query "Crawler.LastCrawl"
```

### ExecuÃ§Ã£o Agendada

O crawler estÃ¡ configurado para executar **diariamente Ã s 00:00 UTC** atravÃ©s da expressÃ£o cron:

```
cron(0 0 * * ? *)
```

**Schedule Details**:
- **Minutos**: 0
- **Horas**: 0 (midnight UTC)
- **Dia do MÃªs**: * (todos os dias)
- **MÃªs**: * (todos os meses)
- **Dia da Semana**: ? (qualquer dia)
- **Ano**: * (todos os anos)

## ğŸ“Š Consultando Dados no Athena

### 1. Verificar Tabela Catalogada

```sql
-- Ver schema da tabela com structs
DESCRIBE bronze_car_data;

-- Ver partiÃ§Ãµes disponÃ­veis
SHOW PARTITIONS bronze_car_data;
```

### 2. Query BÃ¡sica (Colunas Top-Level)

```sql
SELECT 
    carChassis,
    manufacturer,
    model,
    year,
    color,
    ingestion_timestamp
FROM bronze_car_data
WHERE ingest_year = 2025
    AND ingest_month = 10
    AND ingest_day = 30
LIMIT 10;
```

### 3. Query com Campos Aninhados (Dot Notation)

```sql
-- Acessar campos dentro de structs usando dot notation
SELECT 
    carChassis,
    manufacturer,
    
    -- Campos do struct 'metrics'
    metrics.engineTempCelsius,
    metrics.fuelLevelLitres,
    metrics.fuelCapacityLitres,
    metrics.speedKmh,
    metrics.odometerKm,
    metrics.metricTimestamp,
    
    -- Campos do struct 'market'
    market.currentPrice,
    market.currency,
    market.marketRegion,
    market.marketSegment,
    
    -- Campos do struct 'carInsurance'
    carInsurance.policyNumber,
    carInsurance.provider,
    carInsurance.coverageType,
    
    -- Campos do struct 'owner'
    owner.ownerName,
    owner.contactEmail
    
FROM bronze_car_data
WHERE ingest_year = 2025
LIMIT 10;
```

### 4. Query com Filtros em Campos Aninhados

```sql
-- Filtrar por temperatura do motor
SELECT 
    carChassis,
    manufacturer,
    metrics.engineTempCelsius,
    metrics.speedKmh
FROM bronze_car_data
WHERE metrics.engineTempCelsius > 90.0
    AND ingest_year = 2025
ORDER BY metrics.engineTempCelsius DESC;
```

```sql
-- Filtrar por regiÃ£o de mercado
SELECT 
    carChassis,
    manufacturer,
    market.currentPrice,
    market.currency,
    market.marketRegion
FROM bronze_car_data
WHERE market.marketRegion = 'North America'
    AND market.currentPrice > 50000.00
ORDER BY market.currentPrice DESC;
```

### 5. Query Agregada

```sql
-- Temperatura mÃ©dia do motor por fabricante
SELECT 
    manufacturer,
    COUNT(*) as total_records,
    AVG(metrics.engineTempCelsius) as avg_engine_temp,
    AVG(metrics.speedKmh) as avg_speed,
    AVG(market.currentPrice) as avg_price
FROM bronze_car_data
WHERE ingest_year = 2025
GROUP BY manufacturer
ORDER BY avg_price DESC;
```

### 6. Query com ConversÃ£o de Data

```sql
-- Converter metricTimestamp (string) para timestamp
SELECT 
    carChassis,
    manufacturer,
    CAST(metrics.metricTimestamp AS TIMESTAMP) as metric_time,
    metrics.engineTempCelsius,
    DATE_DIFF('hour', 
              CAST(metrics.metricTimestamp AS TIMESTAMP), 
              CURRENT_TIMESTAMP) as hours_ago
FROM bronze_car_data
WHERE ingest_year = 2025
ORDER BY metric_time DESC
LIMIT 20;
```

## ğŸ” Monitoramento e Troubleshooting

### Verificar ExecuÃ§Ã£o do Crawler

```bash
# Ver Ãºltimas 10 execuÃ§Ãµes do crawler
aws glue get-crawler --name datalake-pipeline-bronze-car-data-crawler-dev \
  --query "Crawler.CrawlElapsedTime"

# Ver estatÃ­sticas da Ãºltima execuÃ§Ã£o
aws glue get-crawler --name datalake-pipeline-bronze-car-data-crawler-dev \
  --query "Crawler.LastCrawl.{Status:Status,Duration:LogStream,TablesCreated:TablesCreated,TablesUpdated:TablesUpdated}"
```

### Logs do Crawler no CloudWatch

```bash
# Tail dos logs do crawler
aws logs tail /aws-glue/crawlers --since 30m --follow

# Buscar logs de erro
aws logs filter-log-events \
  --log-group-name /aws-glue/crawlers \
  --filter-pattern "ERROR" \
  --start-time $(date -u -d '1 hour ago' +%s)000
```

### Verificar Tabelas Criadas

```bash
# Listar todas as tabelas no database
aws glue get-tables \
  --database-name datalake-pipeline-catalog-dev \
  --query "TableList[?Name=='bronze_car_data'].[Name,StorageDescriptor.Location,PartitionKeys]"

# Ver schema completo da tabela
aws glue get-table \
  --database-name datalake-pipeline-catalog-dev \
  --name bronze_car_data \
  --query "Table.StorageDescriptor.Columns"
```

### Verificar PartiÃ§Ãµes

```bash
# Listar todas as partiÃ§Ãµes da tabela
aws glue get-partitions \
  --database-name datalake-pipeline-catalog-dev \
  --table-name bronze_car_data \
  --query "Partitions[].{Values:Values,Location:StorageDescriptor.Location}"
```

## ğŸ¯ PrÃ³ximos Passos

### 1. Executar Crawler pela Primeira Vez

```bash
# Iniciar crawler manualmente
aws glue start-crawler --name datalake-pipeline-bronze-car-data-crawler-dev

# Aguardar conclusÃ£o (status: READY)
watch -n 5 'aws glue get-crawler --name datalake-pipeline-bronze-car-data-crawler-dev --query "Crawler.State" --output text'
```

### 2. Validar Tabela no Athena

```sql
-- Ver schema
DESCRIBE bronze_car_data;

-- Contar registros
SELECT COUNT(*) FROM bronze_car_data;

-- Ver sample de dados
SELECT * FROM bronze_car_data LIMIT 5;
```

### 3. Configurar Alertas (Opcional)

```bash
# Criar alarme CloudWatch para falhas do crawler
aws cloudwatch put-metric-alarm \
  --alarm-name bronze-car-data-crawler-failures \
  --alarm-description "Alert when Bronze car_data crawler fails" \
  --metric-name CrawlerFailureRate \
  --namespace AWS/Glue \
  --statistic Average \
  --period 300 \
  --evaluation-periods 1 \
  --threshold 0.5 \
  --comparison-operator GreaterThanThreshold \
  --dimensions Name=CrawlerName,Value=datalake-pipeline-bronze-car-data-crawler-dev
```

## ğŸ“š ReferÃªncias

### AWS Glue Crawler Documentation
- [Glue Crawler Overview](https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html)
- [Schema Change Policy](https://docs.aws.amazon.com/glue/latest/dg/crawler-schema-changes-prevent.html)
- [Crawler Configuration](https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html)

### Athena Documentation
- [Querying Parquet](https://docs.aws.amazon.com/athena/latest/ug/querying-parquet.html)
- [Working with Arrays and Structs](https://docs.aws.amazon.com/athena/latest/ug/rows-and-structs.html)
- [Dot Notation Syntax](https://docs.aws.amazon.com/athena/latest/ug/querying-nested-data.html)

### Terraform Documentation
- [aws_glue_crawler Resource](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/glue_crawler)
- [aws_glue_catalog_database Resource](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/glue_catalog_database)
- [aws_iam_role Resource](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/iam_role)

## âœ… Checklist de ValidaÃ§Ã£o

- [ ] IAM Role criada com permissÃµes corretas
- [ ] Glue Catalog Database criado
- [ ] Bronze car_data Crawler criado
- [ ] Schedule configurado (cron: daily 00:00 UTC)
- [ ] S3 target apontando para `bronze/car_data/`
- [ ] Table prefix `bronze_` configurado
- [ ] Schema change policy: `UPDATE_IN_DATABASE`
- [ ] Recrawl policy: `CRAWL_EVERYTHING`
- [ ] Terraform outputs atualizados
- [ ] Crawler executado manualmente
- [ ] Tabela `bronze_car_data` catalogada
- [ ] PartiÃ§Ãµes detectadas
- [ ] Structs preservados no schema
- [ ] Query Athena funcionando com dot notation
- [ ] DocumentaÃ§Ã£o completa criada

## ğŸ‰ Resultado Final

A infraestrutura Glue estÃ¡ **completamente configurada** para:

âœ… **Descobrir automaticamente** arquivos Parquet na camada Bronze  
âœ… **Preservar estruturas aninhadas** (structs) no schema  
âœ… **Detectar partiÃ§Ãµes HIVE-style** (ingest_year/month/day)  
âœ… **Catalogar metadados** no Glue Data Catalog  
âœ… **Permitir queries Athena** com dot notation para campos nested  
âœ… **Executar diariamente** Ã s 00:00 UTC para detectar novos dados  
âœ… **Gerenciar schema evolution** com MergeNewColumns  

**A Camada Bronze agora Ã© consultÃ¡vel via SQL no Amazon Athena! ğŸš€**

---

**Criado em**: 2025-10-30  
**Terraform Version**: v1.0+  
**AWS Provider**: v5.100.0  
**Status**: âœ… Pronto para produÃ§Ã£o
