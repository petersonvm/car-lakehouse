# üîç An√°lise de Causa Raiz - Falha dos Jobs Gold

**Data:** 2025-11-05  
**Investiga√ß√£o:** Teste E2E - Fase 4  
**Status:** ‚úÖ CAUSA RAIZ IDENTIFICADA

---

## üìä Resumo Executivo

### Sintoma
Jobs da camada Gold **n√£o geraram dados** durante execu√ß√£o do workflow `datalake-pipeline-silver-gold-workflow-dev`.

### Causa Raiz
‚ùå **Inconsist√™ncia de Nomes de Tabelas**: Os 3 jobs Gold est√£o configurados para ler a tabela **`car_silver`**, mas o crawler Silver criou a tabela com o nome **`silver_car_telemetry`**.

### Impacto
üî¥ **CR√çTICO** - Pipeline interrompido na camada Silver, nenhum KPI de neg√≥cio gerado.

---

## üî¨ An√°lise Detalhada

### 1. Estat√≠sticas do Workflow

**Workflow:** `datalake-pipeline-silver-gold-workflow-dev`  
**Run ID:** `wr_2192529795d3eba09fa8eb49bae951782e06dcd670e134eac065bbcfc2899831`

```json
{
    "TotalActions": 15,
    "TimeoutActions": 0,
    "FailedActions": 6,      // ‚ùå 6 a√ß√µes falharam!
    "StoppedActions": 0,
    "SucceededActions": 3,
    "RunningActions": 0,
    "ErroredActions": 0,
    "WaitingActions": 0
}
```

**Interpreta√ß√£o:**
- ‚úÖ 3 a√ß√µes bem-sucedidas: Job Silver + Crawler Silver + Trigger
- ‚ùå 6 a√ß√µes falhadas: 3 Jobs Gold (primeira tentativa) + 3 Jobs Gold (retry com "Max concurrent runs exceeded")

---

### 2. Hist√≥rico de Execu√ß√£o dos Jobs Gold

#### Job 1: `datalake-pipeline-gold-car-current-state-dev`

```json
[
    {
        "JobRunId": "jr_e36ecbb258d478eb83653fc15a05829b197141d2f6ea0b2c54bda492043efd39",
        "JobRunState": "FAILED",
        "StartedOn": "2025-11-05T16:35:09",
        "ErrorMessage": "Max concurrent runs exceeded"
    },
    {
        "JobRunId": "jr_eecf8d46c4e15fa30f90225ffc3d1dfd0fb5825131ca5887999c8436f43fb4d0",
        "JobRunState": "FAILED",
        "StartedOn": "2025-11-05T16:34:39",
        "ErrorMessage": "EntityNotFoundException: Entity Not Found"
    }
]
```

**Cronologia:**
1. **16:34:39** - Primeira tentativa ‚Üí ‚ùå `EntityNotFoundException` (tabela `car_silver` n√£o existe)
2. **16:35:09** - Segunda tentativa ‚Üí ‚ùå `Max concurrent runs exceeded` (retry autom√°tico falhou)

---

#### Job 2: `datalake-pipeline-gold-fuel-efficiency-dev`

```json
[
    {
        "JobRunId": "jr_6a24dc865e12d4bf121876180b146cf48769a4b8c9eee7c4823ff7964dbe42a7",
        "JobRunState": "FAILED",
        "StartedOn": "2025-11-05T16:35:09",
        "ErrorMessage": "Max concurrent runs exceeded"
    },
    {
        "JobRunId": "jr_12650c9da03a4732d01dab8ff183390c04c25b4ae51177bfa84564baf365c404",
        "JobRunState": "FAILED",
        "StartedOn": "2025-11-05T16:34:39",
        "ErrorMessage": "EntityNotFoundException: Entity Not Found"
    }
]
```

**Mesmo padr√£o:** `EntityNotFoundException` seguido de retry com "Max concurrent runs exceeded".

---

#### Job 3: `datalake-pipeline-gold-performance-alerts-slim-dev`

```json
[
    {
        "JobRunId": "jr_777d8d453a48c9947472c0a8069519b58de41bbcdb12898b146a608ada3f6e5c",
        "JobRunState": "FAILED",
        "StartedOn": "2025-11-05T16:35:09",
        "ErrorMessage": "Max concurrent runs exceeded"
    },
    {
        "JobRunId": "jr_9282a8404f6a56af835328039fabedfb3978d6f159f9f1e75665be6c3a2b47a8",
        "JobRunState": "FAILED",
        "StartedOn": "2025-11-05T16:34:39",
        "ErrorMessage": "EntityNotFoundException: Entity Not Found"
    }
]
```

**Conclus√£o:** ‚úÖ **Todos os 3 jobs Gold falharam com o mesmo erro raiz: `EntityNotFoundException`**

---

### 3. Configura√ß√£o dos Jobs Gold

#### Par√¢metros do Job `gold-car-current-state-dev`:

```json
{
    "--silver_database": "datalake-pipeline-catalog-dev",
    "--silver_table": "car_silver",          // ‚ùå TABELA N√ÉO EXISTE!
    "--silver_table_name": "car_silver",     // ‚ùå TABELA N√ÉO EXISTE!
    "--gold_bucket": "datalake-pipeline-gold-dev",
    "--gold_path": "car_current_state",
    "--gold_database": "datalake-pipeline-catalog-dev"
}
```

**Problema:** Jobs tentam ler `car_silver`, mas a tabela real √© `silver_car_telemetry`.

---

### 4. Compara√ß√£o: Esperado vs Real

| Componente | Configura√ß√£o Esperada | Realidade AWS | Status |
|------------|----------------------|----------------|--------|
| **Tabela Silver (Docs)** | `car_silver` | `silver_car_telemetry` | ‚ùå INCONSISTENTE |
| **Tabela Silver (Glue Catalog)** | `car_silver` | `silver_car_telemetry` | ‚ùå INCONSISTENTE |
| **Par√¢metros Jobs Gold** | `--silver_table=car_silver` | `car_silver` (n√£o existe) | ‚ùå INCONSISTENTE |
| **Crawler Silver** | `car_silver_crawler` | `car_silver_crawler` | ‚úÖ CONSISTENTE |
| **Output Crawler** | Deveria criar `car_silver` | Criou `silver_car_telemetry` | ‚ùå INCONSISTENTE |

---

### 5. Linha do Tempo do Teste E2E

```
16:27:07 - Lambda converte JSON ‚Üí Parquet (Bronze) ‚úÖ
16:28:51 - Workflow iniciado ‚úÖ
16:30:44 - Job Silver escreve dados Silver ‚úÖ
16:31:57 - Crawler Silver descobre parti√ß√µes ‚úÖ (cria tabela "silver_car_telemetry")
16:34:39 - Jobs Gold executam em paralelo ‚ùå (EntityNotFoundException √ó 3)
16:35:09 - Jobs Gold tentam retry ‚ùå (Max concurrent runs √ó 3)
16:35:45 - Workflow completa com status "COMPLETED" ‚ö†Ô∏è (mas 6 a√ß√µes falharam!)
```

**Observa√ß√£o Cr√≠tica:** O workflow reportou `COMPLETED` apesar de 40% das a√ß√µes (6/15) terem falhado!

---

## üéØ Causa Raiz Confirmada

### Problema Principal
‚ùå **Nome da Tabela Silver Inconsistente**

**Explica√ß√£o:**
1. O **Crawler Silver** (`car_silver_crawler`) criou a tabela com nome **`silver_car_telemetry`** (provavelmente inferido do path S3 ou configura√ß√£o do crawler)
2. Os **Jobs Gold** est√£o parametrizados para ler **`car_silver`** (via Terraform)
3. Quando os Jobs Gold tentaram executar `glueContext.create_dynamic_frame.from_catalog(database="datalake-pipeline-catalog-dev", table_name="car_silver")`, receberam **`EntityNotFoundException`**

### Problemas Secund√°rios
1. **Falta de Valida√ß√£o:** Workflow reporta `COMPLETED` mesmo com 40% de falhas
2. **Retry Ineficaz:** Jobs Gold tentaram retry autom√°tico mas falharam com "Max concurrent runs exceeded"
3. **Documenta√ß√£o Desatualizada:** Docs usam `car_silver`, mas tabela real √© `silver_car_telemetry`

---

## ‚úÖ Solu√ß√µes Propostas

### Solu√ß√£o 1: Renomear Tabela via AWS Glue (RECOMENDADO)

**A√ß√£o:** Renomear `silver_car_telemetry` ‚Üí `car_silver` no Glue Catalog

**Vantagens:**
- ‚úÖ N√£o requer mudan√ßa de c√≥digo ou Terraform
- ‚úÖ Mant√©m consist√™ncia com documenta√ß√£o
- ‚úÖ Jobs Gold funcionar√£o imediatamente

**Comando:**
```bash
# Op√ß√£o A: Usar AWS CLI para atualizar tabela
aws glue update-table \
  --database-name datalake-pipeline-catalog-dev \
  --table-input '{
    "Name": "car_silver",
    "StorageDescriptor": {...},
    ...
  }' \
  --region us-east-1

# Op√ß√£o B: Deletar tabela incorreta e recriar manualmente
aws glue delete-table \
  --database-name datalake-pipeline-catalog-dev \
  --name silver_car_telemetry \
  --region us-east-1

# Depois criar tabela com nome correto (manualmente via Console ou Terraform)
```

**Desvantagem:**
- ‚ö†Ô∏è Tabela ser√° recriada pelo crawler na pr√≥xima execu√ß√£o (necess√°rio ajustar crawler)

---

### Solu√ß√£o 2: Atualizar Par√¢metros dos Jobs Gold

**A√ß√£o:** Alterar `--silver_table` de `car_silver` ‚Üí `silver_car_telemetry` em todos os 3 jobs Gold

**Terraform:**
```hcl
# terraform/glue_jobs.tf

resource "aws_glue_job" "gold_car_current_state" {
  default_arguments = {
    "--silver_table" = "silver_car_telemetry"  # Era: car_silver
    "--silver_database" = "datalake-pipeline-catalog-dev"
    # ... outros par√¢metros
  }
}

# Repetir para:
# - gold_fuel_efficiency
# - gold_performance_alerts_slim
```

**Vantagens:**
- ‚úÖ Usa nome real da tabela
- ‚úÖ N√£o requer mudan√ßas manuais no Glue Catalog
- ‚úÖ Terraform gerencia configura√ß√£o

**Desvantagens:**
- ‚ö†Ô∏è Requer aplicar Terraform (`terraform apply`)
- ‚ö†Ô∏è Requer update dos jobs na AWS
- ‚ö†Ô∏è Documenta√ß√£o ainda ficar√° inconsistente

---

### Solu√ß√£o 3: Configurar Crawler Silver para Criar Tabela com Nome Espec√≠fico

**A√ß√£o:** Configurar `car_silver_crawler` para criar tabela com nome `car_silver`

**Terraform:**
```hcl
# terraform/crawlers.tf

resource "aws_glue_crawler" "car_silver_crawler" {
  name = "car_silver_crawler"
  
  catalog_target {
    database_name = "datalake-pipeline-catalog-dev"
    tables = ["car_silver"]  # For√ßar nome da tabela
  }
  
  # OU usar TablePrefix
  configuration = jsonencode({
    Version = 1.0
    CrawlerOutput = {
      Tables = { AddOrUpdateBehavior = "MergeNewColumns" }
      Partitions = { AddOrUpdateBehavior = "InheritFromTable" }
    }
  })
}
```

**Vantagens:**
- ‚úÖ Crawler sempre criar√° tabela com nome correto
- ‚úÖ Consist√™ncia entre Terraform e AWS

**Desvantagens:**
- ‚ö†Ô∏è Crawler infere nome do path S3, pode n√£o funcionar
- ‚ö†Ô∏è Requer testar se configura√ß√£o √© respeitada

---

### Solu√ß√£o 4: Criar Tabela Manualmente (Como `car_bronze`)

**A√ß√£o:** Criar tabela `car_silver` manualmente via script SQL ou Terraform, configurar crawler para apenas atualizar parti√ß√µes.

**Vantagens:**
- ‚úÖ Controle total do schema e nome
- ‚úÖ Mesmo padr√£o usado em `car_bronze` (que funcionou perfeitamente)

**Desvantagens:**
- ‚ö†Ô∏è Requer manuten√ß√£o manual do schema se mudar
- ‚ö†Ô∏è Crawler deve ser configurado para n√£o recriar tabela

---

## üèÜ Recomenda√ß√£o Final

### Estrat√©gia Recomendada: **Solu√ß√£o 2 + Solu√ß√£o 4**

1. **Curto Prazo (Hoje):**
   - ‚úÖ Atualizar par√¢metros dos 3 Jobs Gold via AWS CLI para usar `silver_car_telemetry`
   - ‚úÖ Executar Jobs Gold manualmente para validar funcionamento
   - ‚úÖ Executar Crawlers Gold
   - ‚úÖ Completar valida√ß√£o E2E

2. **M√©dio Prazo (Esta Semana):**
   - ‚úÖ Criar tabela `car_silver` manualmente via Terraform (mesmo padr√£o de `car_bronze`)
   - ‚úÖ Deletar tabela `silver_car_telemetry`
   - ‚úÖ Configurar crawler para apenas atualizar parti√ß√µes da tabela existente
   - ‚úÖ Atualizar Jobs Gold de volta para `--silver_table=car_silver`
   - ‚úÖ Aplicar Terraform
   - ‚úÖ Reiniciar teste E2E completo

3. **Longo Prazo (Pr√≥ximas 2 Semanas):**
   - ‚úÖ Padronizar nomenclatura: `car_bronze`, `car_silver`, `car_gold_*`
   - ‚úÖ Atualizar toda documenta√ß√£o
   - ‚úÖ Adicionar valida√ß√µes no workflow (fail se tabelas Gold n√£o forem criadas)
   - ‚úÖ Implementar alarmes CloudWatch para `EntityNotFoundException`

---

## üìù Pr√≥ximos Passos Imediatos

### 1. Update R√°pido (Sem Terraform)
```bash
# Atualizar Job 1
aws glue update-job \
  --job-name datalake-pipeline-gold-car-current-state-dev \
  --job-update '{
    "DefaultArguments": {
      "--silver_table": "silver_car_telemetry",
      "--silver_database": "datalake-pipeline-catalog-dev",
      "--gold_bucket": "datalake-pipeline-gold-dev",
      "--gold_path": "car_current_state",
      "--gold_database": "datalake-pipeline-catalog-dev"
    }
  }' \
  --region us-east-1

# Repetir para outros 2 jobs Gold
```

### 2. Executar Jobs Manualmente
```bash
# Job 1
aws glue start-job-run \
  --job-name datalake-pipeline-gold-car-current-state-dev \
  --region us-east-1

# Job 2
aws glue start-job-run \
  --job-name datalake-pipeline-gold-fuel-efficiency-dev \
  --region us-east-1

# Job 3
aws glue start-job-run \
  --job-name datalake-pipeline-gold-performance-alerts-slim-dev \
  --region us-east-1
```

### 3. Validar Dados Gold
```sql
-- Athena Query 1
SELECT COUNT(*) FROM car_current_state;

-- Athena Query 2
SELECT COUNT(*) FROM fuel_efficiency_metrics;

-- Athena Query 3
SELECT COUNT(*) FROM performance_alerts;
```

---

## üìä M√©tricas de Impacto

| M√©trica | Valor |
|---------|-------|
| **Jobs Afetados** | 3 (100% dos Jobs Gold) |
| **Falhas no Workflow** | 6 (40% das a√ß√µes) |
| **Tempo de Downtime** | ~6.5 minutos (workflow completo sem dados Gold) |
| **Tabelas N√£o Criadas** | 3 (car_current_state, fuel_efficiency_metrics, performance_alerts) |
| **KPIs de Neg√≥cio Perdidos** | 100% (nenhum dado Gold gerado) |
| **Severidade** | üî¥ CR√çTICA |

---

## üîó Refer√™ncias

- **Workflow Terraform:** `terraform/workflow.tf`
- **Jobs Gold Terraform:** `terraform/glue_jobs.tf`
- **Relat√≥rio E2E Completo:** `docs/TESTE_E2E_COMPLETO_RELATORIO.md`
- **Documenta√ß√£o Infraestrutura:** `docs/INFRAESTRUTURA_COMPONENTES.md`
- **AWS Console - Workflow:** https://console.aws.amazon.com/glue/home?region=us-east-1#workflow:name=datalake-pipeline-silver-gold-workflow-dev
- **AWS Console - Jobs Gold:** https://console.aws.amazon.com/glue/home?region=us-east-1#/v2/data-catalog/jobs

---

**An√°lise realizada por:** QA Engineer / SRE  
**Data:** 2025-11-05 20:15:00 UTC-3  
**Status:** ‚úÖ CAUSA RAIZ IDENTIFICADA - AGUARDANDO CORRE√á√ÉO
