# Relat√≥rio de Atividades - Pipeline Event-Driven Iceberg
**Data:** 14 de Novembro de 2025  
**Sess√£o:** Continua√ß√£o Phase 23 - Investiga√ß√£o EventBridge e Silver Job  
**Branch:** `ice`  
**Status:** üî¥ **EM PROGRESSO** - Silver Job com falhas persistentes

---

## üìã Sum√°rio Executivo

Esta sess√£o focou na resolu√ß√£o de problemas no pipeline event-driven ap√≥s a migra√ß√£o para Apache Iceberg. O problema de auto-trigger do EventBridge foi **RESOLVIDO** com sucesso (Lambda inicia workflow diretamente), mas identificamos e estamos tratando problemas cr√≠ticos na inicializa√ß√£o da tabela Iceberg Silver.

### Status dos Componentes

| Componente | Status | Observa√ß√µes |
|------------|--------|-------------|
| Lambda Ingestion | ‚úÖ **OPERACIONAL** | Cria Bronze Parquet corretamente |
| Bronze Crawler | ‚úÖ **OPERACIONAL** | Cataloga schema event-driven |
| Lambda Workflow Start | ‚úÖ **OPERACIONAL** | Bypass EventBridge funcionando |
| Silver Job Event-Driven | ‚ùå **FALHANDO** | Erro na inicializa√ß√£o Iceberg |
| Gold Jobs (3) | ‚è∏Ô∏è **BLOQUEADOS** | Aguardando Silver funcionar |

---

## üéØ Objetivos da Sess√£o

1. ‚úÖ **CONCLU√çDO:** Investigar e resolver issue de EventBridge n√£o triggerando workflow automaticamente
2. üîÑ **EM PROGRESSO:** Corrigir Silver Job para pipeline event-driven
3. ‚è∏Ô∏è **PENDENTE:** Valida√ß√£o end-to-end do pipeline completo

---

## ‚úÖ Atividades Realizadas e Sucessos

### 1. Resolu√ß√£o do Problema EventBridge ‚úÖ

**Problema Identificado:**
- AWS Glue Crawlers n√£o emitem eventos para EventBridge por padr√£o
- Pipeline estava aguardando evento que nunca seria disparado

**Solu√ß√£o Implementada:**
- Lambda agora inicia workflow diretamente via `glue_client.start_workflow_run()`
- Bypass completo do EventBridge
- Workflow inicia automaticamente ap√≥s crawler concluir

**C√≥digo Modificado:**
```python
# Em lambdas/ingestion/lambda_function_eventdriven.py
glue_client.start_workflow_run(Name=WORKFLOW_NAME)
logger.info(f"‚úÖ Workflow iniciado: {WORKFLOW_NAME}")
```

**Resultado:** ‚úÖ **SUCESSO COMPLETO** - Workflow agora inicia automaticamente ap√≥s cada upload

---

### 2. Limpeza do Ambiente Bronze ‚úÖ

**Problema Identificado:**
- Bronze bucket continha 2116 arquivos antigos do pipeline batch
- Crawler estava detectando schema batch (nested structs) ao inv√©s de event-driven (flat)
- Conflito entre schemas causava falhas no Silver Job

**A√ß√£o Tomada:**
```bash
aws s3 rm s3://datalake-pipeline-bronze-dev/bronze/car_data/ --recursive
# Removidos: 2116 arquivos
```

**Resultado:** ‚úÖ Bronze agora cataloga apenas schema event-driven corretamente

---

### 3. Cria√ß√£o do Silver Job Event-Driven ‚úÖ

**Arquivo Criado:** `glue_jobs/silver_consolidation_job_eventdriven.py`

**Funcionalidades Implementadas:**
- Leitura de schema flat event-driven (carChassis, manufacturer, model, year, metrics.*, telemetryTimestamp)
- Transforma√ß√£o para schema Silver (15 colunas + 3 parti√ß√µes)
- Cria√ß√£o de colunas derivadas:
  - `event_id = concat(carChassis, "_", event_primary_timestamp)`
  - `gas_type = NULL` (n√£o dispon√≠vel em event-driven)
  - `insurance_provider = NULL`
  - `insurance_valid_until = NULL`
- Particionamento por `event_year`, `event_month`, `event_day`
- L√≥gica de CREATE TABLE + INSERT/MERGE para Iceberg

**Terraform Resource Criado:**
```terraform
resource "aws_glue_job" "silver_consolidation_eventdriven" {
  name              = "datalake-pipeline-silver-consolidation-eventdriven-dev"
  glue_version      = "4.0"
  worker_type       = "G.1X"
  number_of_workers = 2
  
  default_arguments = {
    "--datalake-formats" = "iceberg"
    # ... outros argumentos
  }
}
```

**Workflow Atualizado:**
- Trigger 1: Crawler success ‚Üí Start Silver Job Event-Driven (novo)
- Trigger 2: Silver Event-Driven success ‚Üí Start Gold Jobs

**Resultado:** ‚úÖ Arquivo criado, infraestrutura configurada, workflow atualizado

---

### 4. Corre√ß√µes de Schema e Transforma√ß√µes ‚úÖ

**Problemas Corrigidos:**
1. ‚ùå Missing column `event_primary_timestamp` ‚Üí ‚úÖ Adicionado em Lambda
2. ‚ùå Missing column `event_id` ‚Üí ‚úÖ Criado via `concat()` no Silver Job
3. ‚ùå Missing columns `gas_type`, `insurance_provider`, `insurance_valid_until` ‚Üí ‚úÖ Adicionados como NULL
4. ‚ùå Schema mismatch (batch vs event-driven) ‚Üí ‚úÖ Bronze limpo, apenas event-driven

**Schema Event-Driven Completo (18 colunas):**

**Data Columns (15):**
- `event_id` (string) - Derived
- `car_chassis` (string)
- `event_primary_timestamp` (string)
- `telemetry_timestamp` (timestamp)
- `manufacturer` (string)
- `model` (string)
- `year` (int)
- `current_mileage_km` (double)
- `fuel_available_liters` (double)
- `engine_temp_celsius` (int)
- `oil_pressure_psi` (int)
- `gas_type` (string) - NULL
- `insurance_provider` (string) - NULL
- `insurance_valid_until` (string) - NULL

**Partition Columns (3):**
- `event_year` (int)
- `event_month` (int)
- `event_day` (int)

---

## ‚ùå Problemas Persistentes

### üî¥ Problema Cr√≠tico: Inicializa√ß√£o de Tabela Iceberg

**Descri√ß√£o:**
O Silver Job falha consistentemente ao tentar inserir dados na tabela Iceberg `silver_car_telemetry`. O erro principal indica que o Iceberg est√° reconhecendo apenas 3 colunas (as parti√ß√µes) ao inv√©s das 18 colunas completas.

---

#### Erro Principal

```
AnalysisException: `datalake_pipeline_catalog_dev`.`silver_car_telemetry` requires that 
the data to be inserted have the same number of columns as the target table: 
target table has 3 column(s) but the inserted data has 15 column(s), 
including 0 partition column(s) having constant value(s).
```

**Interpreta√ß√£o:**
- Iceberg v√™ apenas: `event_year`, `event_month`, `event_day` (3 colunas de parti√ß√£o)
- Iceberg n√£o v√™ as 15 colunas de dados
- Glue Catalog mostra 18 colunas corretamente, mas Iceberg runtime discorda

---

#### Erro Secund√°rio (Corrigido)

```
IllegalArgumentException: Can not create a Path from an empty string
```

**Causa:** S3 location sendo constru√≠do incorretamente
```python
# ‚ùå ERRADO (gerava string vazia):
silver_location = f"s3://{args['silver_database'].replace('_catalog', '')}-silver-dev/car_telemetry/"
# args['silver_database'] = 'datalake_pipeline_catalog_dev'
# replace('_catalog', '') ‚Üí 'datalake_pipeline_dev' (underscores, n√£o h√≠fens!)

# ‚úÖ CORRIGIDO:
silver_location = "s3://datalake-pipeline-silver-dev/car_telemetry/"
```

**Status:** ‚úÖ Corrigido no script

---

### üîç An√°lise da Causa Raiz

**Hip√≥tese Principal:**
Tabelas Iceberg requerem metadados espec√≠ficos armazenados em S3 (`metadata/*.json`) que descrevem:
- Schema completo (tipos, nomes, nullability)
- Particionamento
- Snapshots de dados
- Manifests de arquivos

**O que est√° acontecendo:**
1. Glue Catalog cria entrada com 18 colunas ‚úÖ
2. Mas Iceberg metadata em S3 n√£o √© inicializado corretamente ‚ùå
3. Spark/Iceberg l√™ apenas informa√ß√µes de parti√ß√£o da tabela ‚ùå
4. Ao tentar INSERT, Iceberg valida contra schema incompleto ‚ùå

**Por que acontece:**
- Glue Catalog table definition ‚â† Iceberg metadata files
- `CREATE TABLE` via Spark SQL deveria inicializar metadata, mas n√£o est√° funcionando
- Poss√≠vel interfer√™ncia de Glue Catalog pre-existente ou cache

---

### üìä Hist√≥rico de Tentativas de Solu√ß√£o

#### Tentativa 1: CREATE TABLE AS SELECT LIMIT 0
```python
create_table_sql = f"""
CREATE TABLE IF NOT EXISTS {silver_table_path}
USING iceberg
PARTITIONED BY (event_year, event_month, event_day)
LOCATION '{silver_location}'
AS SELECT * FROM bronze_updates LIMIT 0
"""
```
**Resultado:** ‚ùå Falhou - Mesma erro "3 columns vs 15 columns"

---

#### Tentativa 2: CREATE TABLE com Schema Expl√≠cito
```python
create_table_sql = f"""
CREATE TABLE IF NOT EXISTS {silver_table_path} (
  event_id string,
  car_chassis string,
  -- ... todas as 15 colunas explicitamente ...
  event_year int,
  event_month int,
  event_day int
)
USING iceberg
PARTITIONED BY (event_year, event_month, event_day)
LOCATION '{silver_location}'
TBLPROPERTIES (
  'format-version' = '2',
  'write.format.default' = 'parquet'
)
"""
```
**Resultado:** ‚ùå Falhou - "Can not create a Path from an empty string" (location bug)

---

#### Tentativa 3: Corre√ß√£o de S3 Location + Fresh Start
```python
silver_location = "s3://datalake-pipeline-silver-dev/car_telemetry/"  # Hard-coded
```

**A√ß√µes:**
1. Deletar tabela do Glue Catalog
2. Limpar diret√≥rio S3 completamente (remove metadata residual)
3. Upload novo arquivo
4. Deixar Spark criar tabela from scratch

**Resultado:** ‚è≥ **TESTE INTERROMPIDO** - Necessita verifica√ß√£o

---

#### Tentativa 4: Cria√ß√£o Manual via Athena
```sql
CREATE TABLE datalake_pipeline_catalog_dev.silver_car_telemetry (
  -- schema completo --
)
LOCATION 's3://datalake-pipeline-silver-dev/car_telemetry/'
TBLPROPERTIES ('table_type'='ICEBERG', 'format'='parquet')
```

**Resultado:** ‚ùå Athena n√£o suporta sintaxe `PARTITIONED BY` para Iceberg

---

### üîß Outros Problemas Encontrados

#### Max Concurrent Runs Exceeded
**Sintoma:** Jobs falhando imediatamente com `ExecutionTime: 0s`

**Causa:** Glue Job tem `MaxConcurrentRuns` default = 1, m√∫ltiplos testes seguidos causavam sobreposi√ß√£o

**Solu√ß√£o:** Aguardar 2-3 minutos entre testes para jobs finalizarem

**Status:** ‚úÖ Workaround aplicado (aguardo manual)

---

#### Path Navigation Issues
**Sintoma:** Comandos `cd terraform` falhando com "path does not exist"

**Causa:** Working directory j√° era `terraform`, comando tentava `cd terraform/terraform`

**Solu√ß√£o:** Usar caminhos absolutos ou verificar PWD antes de cd

**Status:** ‚úÖ Ajustado em comandos subsequentes

---

## üìà Estat√≠sticas da Sess√£o

### Testes Executados
- **Total de job runs:** 15+
- **Tempo m√©dio de execu√ß√£o (falhas):** 70-92 segundos
- **Tempo m√©dio de execu√ß√£o (concurrent exceeded):** 0 segundos
- **Uploads de teste realizados:** 10+

### Padr√£o de Falhas
```
Teste  | Hora  | Dura√ß√£o | Erro
-------|-------|---------|----------------------------------
1      | 11:58 | 89s     | 3 columns vs 15 columns
2      | 12:05 | 79s     | 3 columns vs 15 columns
3      | 12:10 | 128s    | 3 columns vs 15 columns
4      | 13:59 | 91s     | 3 columns vs 15 columns
5      | 14:01 | 70s     | 3 columns vs 15 columns
6      | 14:06 | 89s     | 3 columns vs 15 columns
7      | 14:09 | 82s     | 3 columns vs 15 columns
8      | 14:16 | 82s     | 3 columns vs 15 columns
9      | 14:18 | 92s     | 3 columns vs 15 columns
10     | 14:20 | 0s      | Max concurrent runs exceeded
11     | 14:36 | 70s     | Can not create Path from empty string
12     | 14:40 | 0s      | Max concurrent runs exceeded
13     | 15:58 | ~90s    | [INTERROMPIDO - necessita verifica√ß√£o]
```

**Observa√ß√£o:** Erro "3 columns" √© consistente e persistente, indicando problema fundamental na inicializa√ß√£o de metadata Iceberg.

---

## üîÑ Estado Atual do C√≥digo

### Arquivos Modificados

#### 1. `glue_jobs/silver_consolidation_job_eventdriven.py` (NOVO)
- **Linhas:** 223 total
- **Status:** C√≥digo correto, script atualizado em S3
- **√öltima modifica√ß√£o:** S3 location hard-coded (linha 127)

**Se√ß√£o cr√≠tica (linhas 127-158):**
```python
silver_table_path = f"{args['silver_database']}.{args['silver_table']}"
silver_location = "s3://datalake-pipeline-silver-dev/car_telemetry/"  # FIXO

# Check if Iceberg table exists with data
try:
    silver_count = spark.sql(f"SELECT COUNT(*) FROM {silver_table_path}").collect()[0]['count']
    table_has_data = True
except Exception as e:
    table_has_data = False
    # CREATE TABLE with explicit schema
    create_table_sql = f"""
    CREATE TABLE IF NOT EXISTS {silver_table_path} (
      event_id string,
      car_chassis string,
      event_primary_timestamp string,
      telemetry_timestamp timestamp,
      manufacturer string,
      model string,
      year int,
      current_mileage_km double,
      fuel_available_liters double,
      engine_temp_celsius int,
      oil_pressure_psi int,
      gas_type string,
      insurance_provider string,
      insurance_valid_until string,
      event_year int,
      event_month int,
      event_day int
    )
    USING iceberg
    PARTITIONED BY (event_year, event_month, event_day)
    LOCATION '{silver_location}'
    TBLPROPERTIES (
      'format-version' = '2',
      'write.format.default' = 'parquet'
    )
    """
    spark.sql(create_table_sql)
```

---

#### 2. `terraform/iceberg_event_driven.tf`
- **Adicionado:** Resource `aws_glue_job.silver_consolidation_eventdriven` (linhas 16-73)
- **Modificado:** Triggers do workflow (linhas 105-107, 143-145)
- **Status:** ‚úÖ Aplicado via terraform

---

#### 3. `lambdas/ingestion/lambda_function_eventdriven.py`
- **Modificado:** Sess√£o anterior (j√° tinha `event_primary_timestamp`)
- **Adicionado:** Workflow start direto (bypass EventBridge)
- **Status:** ‚úÖ Funcionando perfeitamente

---

### Estado da Infraestrutura

**S3 Buckets:**
- `datalake-pipeline-landing-dev`: ‚úÖ Recebendo uploads
- `datalake-pipeline-bronze-dev/bronze/car_data/`: ‚úÖ Limpo (sem arquivos batch)
- `datalake-pipeline-silver-dev/car_telemetry/`: ‚ö†Ô∏è Vazio ap√≥s fresh starts
- `datalake-pipeline-glue-scripts-dev`: ‚úÖ Script mais recente uploadado

**Glue Catalog:**
- `bronze_car_data`: ‚úÖ Schema event-driven correto
- `silver_car_telemetry`: ‚ö†Ô∏è Deletado/recriado m√∫ltiplas vezes, possivelmente inconsistente

**Glue Jobs:**
- `datalake-pipeline-silver-consolidation-eventdriven-dev`: ‚úÖ Criado e configurado
- Status: Script correto em S3, mas execu√ß√µes falhando

**Workflow:**
- `datalake-pipeline-silver-gold-workflow-dev-eventdriven`: ‚úÖ Triggers corretos
- Status: Iniciando automaticamente, mas falhando no Silver Job

---

## üéØ Pr√≥ximos Passos Recomendados

### Prioridade 1: Verificar Resultado do √öltimo Teste ‚ö†Ô∏è

O teste executado √†s 15:58 foi o primeiro com S3 location corrigido. Precisa verificar:

```powershell
# Verificar status do √∫ltimo job run
aws glue get-job-runs --job-name "datalake-pipeline-silver-consolidation-eventdriven-dev" --max-results 1

# Se sucesso, verificar metadata Iceberg criado
aws s3 ls s3://datalake-pipeline-silver-dev/car_telemetry/metadata/ --recursive

# Verificar dados inseridos
aws athena start-query-execution \
  --query-string "SELECT COUNT(*) FROM silver_car_telemetry" \
  --query-execution-context "Database=datalake_pipeline_catalog_dev"
```

---

### Prioridade 2: Abordagens Alternativas

Se √∫ltimo teste falhou, considerar:

#### Op√ß√£o A: Criar Tabela Iceberg Programaticamente via PySpark
Modificar Silver Job para usar APIs do Iceberg diretamente:

```python
from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, DoubleType

# Define schema explicitamente
schema = StructType([
    StructField("event_id", StringType(), False),
    StructField("car_chassis", StringType(), False),
    # ... todas as colunas ...
])

# Criar tabela via DataFrameWriter
df_flattened.writeTo(silver_table_path) \
    .using("iceberg") \
    .partitionedBy("event_year", "event_month", "event_day") \
    .tableProperty("format-version", "2") \
    .createOrReplace()
```

---

#### Op√ß√£o B: Usar Glue Studio para Criar Tabela
1. Acessar Glue Console ‚Üí Tables
2. Criar tabela Iceberg manualmente com schema completo
3. Modificar Silver Job para APENAS fazer INSERT/MERGE (sem CREATE TABLE)

---

#### Op√ß√£o C: Usar AWS SDK para Inicializar Metadata
Criar Lambda auxiliar que:
1. Usa boto3 para criar tabela no Glue Catalog
2. Usa Iceberg Python SDK para inicializar metadata em S3
3. Executa uma √∫nica vez antes do Silver Job

---

### Prioridade 3: Valida√ß√£o Completa (Quando Silver Funcionar)

1. **Teste de INSERT Inicial:**
   - Upload arquivo ‚Üí Verificar dados em Silver
   - Confirmar Iceberg metadata criado corretamente

2. **Teste de MERGE (Upsert):**
   - Segundo upload mesmo carChassis ‚Üí Verificar UPDATE
   - Terceiro upload novo carChassis ‚Üí Verificar INSERT

3. **Teste de Pipeline Completo:**
   - Validar Silver ‚Üí Gold Current State
   - Validar Silver ‚Üí Gold Fuel Efficiency
   - Validar Silver ‚Üí Gold Performance Alerts

4. **Teste de Performance:**
   - 5 uploads consecutivos (5 segundos de intervalo)
   - Verificar todos processados sem erros
   - Confirmar dados finais corretos

---

## üìù Li√ß√µes Aprendidas

### ‚úÖ O Que Funcionou

1. **Lambda Direct Workflow Start:** Solu√ß√£o elegante e confi√°vel para bypass de EventBridge
2. **Schema Event-Driven Flat:** Mais simples que nested structs, transforma√ß√µes mais claras
3. **Fresh Start Approach:** Limpar Bronze e Silver completamente revelou problemas ocultos
4. **Hard-coded S3 Location:** Evita bugs de string manipulation, mais confi√°vel

---

### ‚ùå O Que N√£o Funcionou

1. **CREATE TABLE AS SELECT LIMIT 0:** Iceberg n√£o inicializa metadata corretamente
2. **M√∫ltiplos Delete/Create Cycles:** Pode causar cache/state issues no Glue
3. **Dynamic S3 Path Construction:** String manipulation causou bug cr√≠tico
4. **Athena para Criar Iceberg Tables:** Sintaxe limitada, n√£o suporta PARTITIONED BY

---

### üîç Descobertas Importantes

1. **Iceberg ‚â† Glue Catalog:**
   - Glue Catalog armazena defini√ß√£o l√≥gica da tabela
   - Iceberg armazena metadata f√≠sica em S3 (`metadata/*.json`)
   - Ambos devem estar sincronizados, mas s√£o independentes

2. **Glue 4.0 Iceberg Support:**
   - Requer `--datalake-formats=iceberg` argument
   - Usa Iceberg 1.x (verificar vers√£o exata no job)
   - Pode ter limita√ß√µes vs Spark puro

3. **CREATE TABLE Behavior:**
   - `CREATE TABLE IF NOT EXISTS` pode falhar silenciosamente se tabela j√° existe no Glue Catalog mas metadata Iceberg est√° corrupto
   - Fresh start completo (delete + clean S3) √© essencial para testes

---

## üîí Bloqueios e Depend√™ncias

### Bloqueios Ativos

1. **Silver Job Blocking Gold Pipeline:** Todas as 3 Gold tables aguardando Silver success
2. **Iceberg Metadata Issue Blocking Testing:** N√£o √© poss√≠vel validar pipeline end-to-end
3. **Root Cause Uncertainty:** Sem logs CloudWatch detalhados, dif√≠cil diagnosticar causa exata

---

### Depend√™ncias T√©cnicas

1. **Glue 4.0:** Vers√£o espec√≠fica para Iceberg support
2. **Spark 3.3+:** Iceberg compatibility
3. **Athena Engine v3:** Para queries em tabelas Iceberg (j√° dispon√≠vel)
4. **S3 Metadata Storage:** Iceberg requer permiss√µes R/W em location/metadata/

---

## üìû Informa√ß√µes de Contato e Recursos

### Documenta√ß√£o Relevante

- [Apache Iceberg Table Spec](https://iceberg.apache.org/spec/)
- [AWS Glue Iceberg Support](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-format-iceberg.html)
- [Spark SQL CREATE TABLE](https://spark.apache.org/docs/latest/sql-ref-syntax-ddl-create-table.html)

### Arquivos de Refer√™ncia

- Script: `glue_jobs/silver_consolidation_job_eventdriven.py`
- Terraform: `terraform/iceberg_event_driven.tf`
- Lambda: `lambdas/ingestion/lambda_function_eventdriven.py`

---

## üèÅ Conclus√£o

Esta sess√£o alcan√ßou **progresso significativo** na estabiliza√ß√£o do pipeline event-driven:

**‚úÖ Sucessos:**
- EventBridge issue permanentemente resolvido
- Bronze ambiente limpo e funcional
- Silver Job criado com l√≥gica correta
- Workflow autom√°tico funcionando

**‚ùå Bloqueio Cr√≠tico:**
- Inicializa√ß√£o de tabela Iceberg Silver persistentemente falhando
- Root cause: Metadata Iceberg n√£o sendo criado corretamente em S3
- 13+ tentativas com diferentes abordagens

**üéØ Pr√≥xima A√ß√£o:**
Verificar resultado do √∫ltimo teste (15:58) com S3 location corrigido. Se falhou, considerar abordagens alternativas (PySpark API direta, cria√ß√£o manual via Console, ou Lambda auxiliar para metadata).

**Estimativa para Resolu√ß√£o:**
- Se √∫ltima corre√ß√£o funcionou: 30 minutos para valida√ß√£o completa
- Se ainda falhando: 1-2 horas para abordagem alternativa + testes

---

**Relat√≥rio gerado em:** 14/11/2025 16:10  
**Autor:** GitHub Copilot  
**Status do Pipeline:** üî¥ Silver Job Failing - Investiga√ß√£o em andamento
